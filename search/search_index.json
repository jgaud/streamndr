{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"StreamNDR","text":"<p>This site contains the documentation for <code>StreamNDR</code>, a Python library based on river which aims to implement novelty detection algorithm for data streams. The library is open-source and availabble on Github.</p>"},{"location":"#what-is-novelty-detection","title":"What is novelty detection?","text":"<p>Novelty Detection consists of the task of detecting novelty concepts (or classes) in a data stream, that is, classes that the model has not seen before. In order to do so, the algorithms often implement an offline phase, where ther learn the known classes in supervised manner, followed by an online phase, where the algorithm will try to label and detect novel classes within the stream of data. </p>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#installation","title":"\ud83d\udee0 Installation","text":"<p>Note: StreamNDR is intended to be used with Python 3.6 or above and requires the package ClusOpt-Core which requires a C/C++ compiler (such as gcc) and the Boost.Thread library to build. To install the Boost.Thread library on Debian systems, the following command can be used:</p> <pre><code>sudo apt install libboost-thread-dev\n</code></pre> <p>The package can be installed simply with <code>pip</code> : <pre><code>pip install streamndr\n</code></pre></p>"},{"location":"getting_started/#quickstart","title":"\u26a1\ufe0f Quickstart","text":"<p>As a quick example, we'll train two models (MINAS and ECSMiner-WF) to classify a synthetic dataset created using RandomRBF. The models are trained on only two of the four generated classes ([0,1]) and will try to detect the other classes ([2,3]) as novelty patterns in the dataset in an online fashion.</p> <p>Let's first generate the dataset. <pre><code>import numpy as np\nfrom river.datasets import synth\n\nds = synth.RandomRBF(seed_model=42, seed_sample=42, n_classes=4, n_features=5, n_centroids=10)\n\noffline_size = 1000\nonline_size = 5000\nX_train = []\ny_train = []\nX_test = []\ny_test = []\n\nfor x,y in ds.take(10*(offline_size+online_size)):\n\n    #Create our training data (known classes)\n    if len(y_train) &lt; offline_size:\n        if y == 0 or y == 1: #Only showing two first classes in the training set\n            X_train.append(np.array(list(x.values())))\n            y_train.append(y)\n\n    #Create our online stream of data\n    elif len(y_test) &lt; online_size:\n        X_test.append(x)\n        y_test.append(y)\n\n    else:\n        break\n\nX_train = np.array(X_train)\ny_train = np.array(y_train)\n</code></pre></p>"},{"location":"getting_started/#minas","title":"MINAS","text":"<p>Let's train our MINAS model on the offline (known) data. <pre><code>from streamndr.model import Minas\nclf = Minas(kini=10, cluster_algorithm='kmeans', \n            window_size=100, threshold_strategy=1, threshold_factor=1.1, \n            min_short_mem_trigger=100, min_examples_cluster=50, verbose=1, random_state=42)\n\nclf.learn_many(np.array(X_train), np.array(y_train)) #learn_many expects numpy arrays or pandas dataframes\n</code></pre></p> <p>Let's now test our algorithm in an online fashion, note that our unsupervised clusters are automatically updated with the call to <code>predict_one</code>.</p> <p><pre><code>from streamndr.metrics import ConfusionMatrixNovelty, MNew, FNew, ErrRate\n\nknown_classes = [0,1]\n\nconf_matrix = ConfusionMatrixNovelty(known_classes)\nm_new = MNew(known_classes)\nf_new = FNew(known_classes)\nerr_rate = ErrRate(known_classes)\n\nfor x, y_true in zip(X_test, y_test):\n\n    y_pred = clf.predict_one(x) #predict_one takes python dictionaries as per River API\n\n    if y_pred is not None: #Update our metrics\n        conf_matrix = conf_matrix.update(y_true, y_pred[0])\n        m_new = m_new.update(y_true, y_pred[0])\n        f_new = f_new.update(y_true, y_pred[0])\n        err_rate = err_rate.update(y_true, y_pred[0])\n</code></pre> Looking at the confusion matrix below, with -1 being the unknown class, we can see that our model succesfully detected some of our novel classes ([3,4]) as novel concepts. The percentage of novel classes instances misclassified as known is also fairly low (2.05%), but we did classified a lot of our known classes samples as novel ones (54.13%). Of course, the hyperparameters of the model can be tuned a lot more to get better results. <pre><code>print(conf_matrix)\nprint(m_new) #Percentage of novel class instances misclassified as known.\nprint(f_new) #Percentage of known classes misclassified as novel.\nprint(err_rate) #Total misclassification error percentage\n</code></pre></p> -1 0 1 2 3 -1 0 0 0 0 0 0 722 341 33 10 44 1 1155 19 1296 58 4 2 386 7 19 312 0 3 172 1 0 0 421 <p>MNew: 2.05%  FNew: 54.13%  ErrRate: 41.44% </p>"},{"location":"getting_started/#ecsminer-wf","title":"ECSMiner-WF","text":"<p>Let's train our model on the offline (known) data.</p> <p><pre><code>from streamndr.model import ECSMinerWF\nclf = ECSMinerWF(K=5, min_examples_cluster=5, verbose=1, random_state=42, ensemble_size=20)\nclf.learn_many(np.array(X_train), np.array(y_train))\n</code></pre> Once again, let's use our model in an online fashion. <pre><code>conf_matrix = ConfusionMatrixNovelty(known_classes)\nm_new = MNew(known_classes)\nf_new = FNew(known_classes)\nerr_rate = ErrRate(known_classes)\n\nfor x, y_true in zip(X_test, y_test):\n\n    y_pred = clf.predict_one(x) #predict_one takes python dictionaries as per River API\n\n    if y_pred is not None: #Update our metrics\n        conf_matrix = conf_matrix.update(y_true, y_pred[0])\n        m_new = m_new.update(y_true, y_pred[0])\n        f_new = f_new.update(y_true, y_pred[0])\n        err_rate = err_rate.update(y_true, y_pred[0])\n</code></pre></p> <p>The confusion matrix shows us that ECSMiner successfully detected some of the samples of our third class as novel concepts, but not our second class. Again, a lot more tuning can be done to the hyperparameters to improve the results. It is to be noted too that ECSMiner is originally an algorithm that receives feedback (true values) back from the user. With feedback, the algorithm would perform a lot better. <pre><code>print(conf_matrix)\nprint(m_new) #Percentage of novel class instances misclassified as known.\nprint(f_new) #Percentage of known classes misclassified as novel.\nprint(err_rate) #Total misclassification error percentage\n</code></pre></p> -1 0 1 2 3 4 5 6 -1 0 0 0 0 0 0 0 0 0 92 835 219 3 0 0 1 0 1 216 180 2131 0 0 1 2 2 2 44 6 673 0 0 1 0 0 3 106 280 88 0 67 23 19 11 4 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 <p>MNew: 79.44%  FNew: 8.61%  ErrRate: 35.26% </p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>metrics<ul> <li>cer</li> <li>confusion</li> <li>err_rate</li> <li>f_new</li> <li>m_new</li> <li>ttd</li> </ul> </li> <li>model<ul> <li>ecsminerwf</li> <li>minas</li> </ul> </li> <li>utils<ul> <li>data_structure</li> </ul> </li> </ul>"},{"location":"reference/metrics/cer/","title":"cer","text":""},{"location":"reference/metrics/cer/#streamndr.metrics.cer.CER","title":"<code>CER</code>","text":"<p>             Bases: <code>MultiClassMetric</code></p> <p>Combined Error Rate (CER), defined as the average of the weighted rate of false positive and false negative per class [1].</p> <p>[1] E. R. Faria, I. J. C. R. Gon\u00e7alves, J. Gama and A. C. P. L. F. Carvalho, \"Evaluation Methodology for Multiclass Novelty Detection Algorithms,\"      2013 Brazilian Conference on Intelligent Systems, Fortaleza, Brazil, 2013, pp. 19-25, doi: 10.1109/BRACIS.2013.12.</p> <p>Parameters:</p> Name Type Description Default <code>known_classes</code> <code>list of int</code> <p>List of known labels, the labels the algorithm knows prior to the online phase</p> required <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Optional, can specify an already existing confusion matrix instead of creating a new one for the metric</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Confusion matrix</p> Source code in <code>streamndr/metrics/cer.py</code> <pre><code>class CER(metrics.base.MultiClassMetric):\n    \"\"\"Combined Error Rate (CER), defined as the average of the weighted rate of false positive and false negative per class [1].\n\n    [1] E. R. Faria, I. J. C. R. Gon\u00e7alves, J. Gama and A. C. P. L. F. Carvalho, \"Evaluation Methodology for Multiclass Novelty Detection Algorithms,\" \n        2013 Brazilian Conference on Intelligent Systems, Fortaleza, Brazil, 2013, pp. 19-25, doi: 10.1109/BRACIS.2013.12.\n\n    Parameters\n    ----------\n    known_classes : list of int\n        List of known labels, the labels the algorithm knows prior to the online phase\n    cm : ConfusionMatrixNovelty\n        Optional, can specify an already existing confusion matrix instead of creating a new one for the metric\n\n    Attributes\n    ----------\n    cm : ConfusionMatrixNovelty\n        Confusion matrix\n    \"\"\"\n    def __init__(self, known_classes, cm: ConfusionMatrixNovelty = None):\n        if cm is None:\n            cm = ConfusionMatrixNovelty(known_classes)\n\n        super(metrics.base.MultiClassMetric, self).__init__(cm)\n\n    def get(self):\n        associated_classes_conf_matrix = self.cm.get_associated_classes()\n        total = 0\n\n        for c in self.cm.classes:\n            try:\n                fp = associated_classes_conf_matrix.false_positives(c)\n                tn = associated_classes_conf_matrix.true_negatives(c)\n                fn = associated_classes_conf_matrix.false_negatives(c)\n                tp = associated_classes_conf_matrix.true_positives(c)\n\n                fpr = fp / (fp + tn)\n                fnr = fn / (fn + tp)\n\n                w = associated_classes_conf_matrix.support(c) / associated_classes_conf_matrix.total_weight\n\n                total += (w * fpr) + (w * fnr)\n\n            except ZeroDivisionError:\n                continue\n\n\n        return total / 2\n\n    def get_aic(self):\n        \"\"\"Computes the Akaike Information Criterion (AIC) as defined in [1], which measures the complexity of the model using the CER and the number of classes detected.\n\n        Returns\n        -------\n        float\n            The Akaike Information Criterion (AIC)\n        \"\"\"\n        all_classes = self.cm.classes\n\n        if -1 in all_classes:\n            all_classes.remove(-1)\n\n        num_classes_detected = 0\n        N = 0\n\n        for cl in all_classes:\n            N += self.cm.sum_col[cl]\n            if self.cm.sum_col[cl] &gt; 0:\n                num_classes_detected += 1\n\n        try:\n            return -2 * math.log(1-self.get()) + 2 * num_classes_detected / math.log(N)\n        except:\n            return 0.0\n</code></pre>"},{"location":"reference/metrics/cer/#streamndr.metrics.cer.CER.get_aic","title":"<code>get_aic()</code>","text":"<p>Computes the Akaike Information Criterion (AIC) as defined in [1], which measures the complexity of the model using the CER and the number of classes detected.</p> <p>Returns:</p> Type Description <code>float</code> <p>The Akaike Information Criterion (AIC)</p> Source code in <code>streamndr/metrics/cer.py</code> <pre><code>def get_aic(self):\n    \"\"\"Computes the Akaike Information Criterion (AIC) as defined in [1], which measures the complexity of the model using the CER and the number of classes detected.\n\n    Returns\n    -------\n    float\n        The Akaike Information Criterion (AIC)\n    \"\"\"\n    all_classes = self.cm.classes\n\n    if -1 in all_classes:\n        all_classes.remove(-1)\n\n    num_classes_detected = 0\n    N = 0\n\n    for cl in all_classes:\n        N += self.cm.sum_col[cl]\n        if self.cm.sum_col[cl] &gt; 0:\n            num_classes_detected += 1\n\n    try:\n        return -2 * math.log(1-self.get()) + 2 * num_classes_detected / math.log(N)\n    except:\n        return 0.0\n</code></pre>"},{"location":"reference/metrics/confusion/","title":"confusion","text":""},{"location":"reference/metrics/confusion/#streamndr.metrics.confusion.ConfusionMatrixNovelty","title":"<code>ConfusionMatrixNovelty</code>","text":"<p>             Bases: <code>ConfusionMatrix</code></p> <p>Confusion Matrix for novelty detection in data streams.</p> <p>Parameters:</p> Name Type Description Default <code>known_classes</code> <code>list of int</code> <p>List of known labels, the labels the algorithm knows prior to the online phase</p> required <p>Attributes:</p> Name Type Description <code>novel_cm</code> <code>ConfusionMatrix</code> <p>Binary confusion matrix representing the problem in a binary manner, including class 0 (known) and class 1 (novelty)</p> <code>nc_samples</code> <code>int</code> <p>Number of samples representing a novelty</p> <code>fe</code> <code>int</code> <p>Known samples that have been classified as a known class other than its ground truth</p> Source code in <code>streamndr/metrics/confusion.py</code> <pre><code>class ConfusionMatrixNovelty(metrics.confusion.ConfusionMatrix):\n    \"\"\"Confusion Matrix for novelty detection in data streams.\n\n    Parameters\n    ----------\n    known_classes : list of int\n        List of known labels, the labels the algorithm knows prior to the online phase\n\n    Attributes\n    ----------\n    novel_cm : river.metrics.Confusion.ConfusionMatrix\n        Binary confusion matrix representing the problem in a binary manner, including class 0 (known) and class 1 (novelty)\n    nc_samples : int\n        Number of samples representing a novelty\n    fe : int\n        Known samples that have been classified as a known class other than its ground truth\n    \"\"\"\n    def __init__(self, known_classes):\n        super().__init__(known_classes)\n        self.novel_cm = metrics.confusion.ConfusionMatrix()\n        self.nc_samples = 0\n        self.fe = 0\n\n    def get_associated_classes(self):\n        \"\"\"Computes the associated known class to each novelty pattern discovered, as described in [1], by using the real class most represented in each novelty pattern.\n        Ignores the unkown samples (label -1).\n\n        [1] E. R. Faria, I. J. C. R. Gon\u00e7alves, J. Gama and A. C. P. L. F. Carvalho, \"Evaluation Methodology for Multiclass Novelty Detection Algorithms,\" \n        2013 Brazilian Conference on Intelligent Systems, Fortaleza, Brazil, 2013, pp. 19-25, doi: 10.1109/BRACIS.2013.12.\n\n        Returns\n        -------\n        ConfusionMatrixNovelty\n            The confusion matrix using the most represented known class for each of the novelty pattern reported\n        \"\"\"\n        associated_classes_conf_matrix = ConfusionMatrixNovelty(self._init_classes)\n        unknown_classes = [x for x in self.classes if x not in self._init_classes.union({-1})]\n\n        for cl in self.classes:\n            col = [int(self.data[row][cl]) for row in self.classes]\n\n            #If the class is a novelty pattern, we select the real class most represented within the novelty pattern\n            if cl in unknown_classes:\n                index_max = col.index(max(col))\n                pred = self.classes[index_max]\n\n                for row in self.classes:\n                    associated_classes_conf_matrix.update(row, pred, self.data[row][cl])\n            elif cl != -1:\n                for row in self.classes:\n                    associated_classes_conf_matrix.update(row, cl, self.data[row][cl])\n\n        return associated_classes_conf_matrix\n\n\n    def update(self, y_true, y_pred, sample_weight=1.0):\n        super().update(y_true, y_pred, sample_weight)\n\n        known_class = int(y_true in self._init_classes)\n        pred_known_class = int(y_pred in self._init_classes)\n\n        if known_class == 0:\n            self.nc_samples += 1\n        elif known_class == pred_known_class == 1 and y_true != y_pred: #If the prediction is not a novelty, but we predicted the wrong class\n            self.fe += 1\n\n        self.novel_cm.update(1-known_class, 1-pred_known_class)\n\n        return self\n\n    def revert(self, y_true, y_pred, sample_weight=1.0):\n        super.revert(self, y_true, y_pred, sample_weight)\n\n        known_class = int(y_true in self._init_classes)\n        pred_known_class = int(y_pred in self._init_classes)\n\n        if known_class == 1:\n            self.nc_samples -= 1\n            if pred_known_class == 1 and y_true != y_pred:\n                self.fe -= 1\n\n        self.novel_cm.revert(1-known_class, 1-pred_known_class)\n\n        return self\n\n    def true_positives_novelty(self):\n        return self.novel_cm.true_positives(1)\n\n    def true_negatives_novelty(self):\n        return self.novel_cm.true_negatives(1)\n\n    def false_positives_novelty(self):\n        return self.novel_cm.false_positives(1)\n\n    def false_negatives_novelty(self):\n        return self.novel_cm.false_negatives(1)\n</code></pre>"},{"location":"reference/metrics/confusion/#streamndr.metrics.confusion.ConfusionMatrixNovelty.get_associated_classes","title":"<code>get_associated_classes()</code>","text":"<p>Computes the associated known class to each novelty pattern discovered, as described in [1], by using the real class most represented in each novelty pattern. Ignores the unkown samples (label -1).</p> <p>[1] E. R. Faria, I. J. C. R. Gon\u00e7alves, J. Gama and A. C. P. L. F. Carvalho, \"Evaluation Methodology for Multiclass Novelty Detection Algorithms,\"  2013 Brazilian Conference on Intelligent Systems, Fortaleza, Brazil, 2013, pp. 19-25, doi: 10.1109/BRACIS.2013.12.</p> <p>Returns:</p> Type Description <code>ConfusionMatrixNovelty</code> <p>The confusion matrix using the most represented known class for each of the novelty pattern reported</p> Source code in <code>streamndr/metrics/confusion.py</code> <pre><code>def get_associated_classes(self):\n    \"\"\"Computes the associated known class to each novelty pattern discovered, as described in [1], by using the real class most represented in each novelty pattern.\n    Ignores the unkown samples (label -1).\n\n    [1] E. R. Faria, I. J. C. R. Gon\u00e7alves, J. Gama and A. C. P. L. F. Carvalho, \"Evaluation Methodology for Multiclass Novelty Detection Algorithms,\" \n    2013 Brazilian Conference on Intelligent Systems, Fortaleza, Brazil, 2013, pp. 19-25, doi: 10.1109/BRACIS.2013.12.\n\n    Returns\n    -------\n    ConfusionMatrixNovelty\n        The confusion matrix using the most represented known class for each of the novelty pattern reported\n    \"\"\"\n    associated_classes_conf_matrix = ConfusionMatrixNovelty(self._init_classes)\n    unknown_classes = [x for x in self.classes if x not in self._init_classes.union({-1})]\n\n    for cl in self.classes:\n        col = [int(self.data[row][cl]) for row in self.classes]\n\n        #If the class is a novelty pattern, we select the real class most represented within the novelty pattern\n        if cl in unknown_classes:\n            index_max = col.index(max(col))\n            pred = self.classes[index_max]\n\n            for row in self.classes:\n                associated_classes_conf_matrix.update(row, pred, self.data[row][cl])\n        elif cl != -1:\n            for row in self.classes:\n                associated_classes_conf_matrix.update(row, cl, self.data[row][cl])\n\n    return associated_classes_conf_matrix\n</code></pre>"},{"location":"reference/metrics/err_rate/","title":"err_rate","text":""},{"location":"reference/metrics/err_rate/#streamndr.metrics.err_rate.ErrRate","title":"<code>ErrRate</code>","text":"<p>             Bases: <code>MultiClassMetric</code></p> <p>Error rate, represents the total misclassification error percentage.</p> <p>Parameters:</p> Name Type Description Default <code>known_classes</code> <code>list of int</code> <p>List of known labels, the labels the algorithm knows prior to the online phase</p> required <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Optional, can specify an already existing confusion matrix instead of creating a new one for the metric</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Confusion matrix</p> Source code in <code>streamndr/metrics/err_rate.py</code> <pre><code>class ErrRate(metrics.base.MultiClassMetric):\n    \"\"\"Error rate, represents the total misclassification error percentage.\n\n    Parameters\n    ----------\n    known_classes : list of int\n        List of known labels, the labels the algorithm knows prior to the online phase\n    cm : ConfusionMatrixNovelty\n        Optional, can specify an already existing confusion matrix instead of creating a new one for the metric\n\n    Attributes\n    ----------\n    cm : ConfusionMatrixNovelty\n        Confusion matrix\n    \"\"\"\n    def __init__(self, known_classes, cm: ConfusionMatrixNovelty = None):\n        if cm is None:\n            cm = ConfusionMatrixNovelty(known_classes)\n\n        super(metrics.base.MultiClassMetric, self).__init__(cm)\n\n    def get(self):\n        fp = self.cm.false_positives_novelty() #Number of known class samples wrongly classified as novelties\n        fn = self.cm.false_negatives_novelty() #Number of novelties wrongly classified as known\n\n        try:\n            return (fp + fn + self.cm.fe) / self.cm.n_samples\n        except ZeroDivisionError:\n            return 0.0\n</code></pre>"},{"location":"reference/metrics/f_new/","title":"f_new","text":""},{"location":"reference/metrics/f_new/#streamndr.metrics.f_new.FNew","title":"<code>FNew</code>","text":"<p>             Bases: <code>MultiClassMetric</code></p> <p>Metric F_new, which represents the percentage of known classes misclassified as novel.</p> <p>Parameters:</p> Name Type Description Default <code>known_classes</code> <code>list of int</code> <p>List of known labels, the labels the algorithm knows prior to the online phase</p> required <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Optional, can specify an already existing confusion matrix instead of creating a new one for the metric</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Confusion matrix</p> Source code in <code>streamndr/metrics/f_new.py</code> <pre><code>class FNew(metrics.base.MultiClassMetric):\n    \"\"\"Metric F_new, which represents the percentage of known classes misclassified as novel.\n\n    Parameters\n    ----------\n    known_classes : list of int\n        List of known labels, the labels the algorithm knows prior to the online phase\n    cm : ConfusionMatrixNovelty\n        Optional, can specify an already existing confusion matrix instead of creating a new one for the metric\n\n    Attributes\n    ----------\n    cm : ConfusionMatrixNovelty\n        Confusion matrix\n    \"\"\"\n    def __init__(self, known_classes, cm: ConfusionMatrixNovelty = None):\n        if cm is None:\n            cm = ConfusionMatrixNovelty(known_classes)\n\n        super(metrics.base.MultiClassMetric, self).__init__(cm)\n\n    def get(self):\n        fp = self.cm.false_positives_novelty() #Number of known class samples wrongly classified as novelties\n\n        try:\n            return fp / (self.cm.n_samples - self.cm.nc_samples)\n        except ZeroDivisionError:\n            return 0.0\n</code></pre>"},{"location":"reference/metrics/m_new/","title":"m_new","text":""},{"location":"reference/metrics/m_new/#streamndr.metrics.m_new.MNew","title":"<code>MNew</code>","text":"<p>             Bases: <code>MultiClassMetric</code></p> <p>Metric M_new, which represents the percentage of novel class instances misclassified as known.</p> <p>Parameters:</p> Name Type Description Default <code>known_classes</code> <code>list of int</code> <p>List of known labels, the labels the algorithm knows prior to the online phase</p> required <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Optional, can specify an already existing confusion matrix instead of creating a new one for the metric</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Confusion matrix</p> Source code in <code>streamndr/metrics/m_new.py</code> <pre><code>class MNew(metrics.base.MultiClassMetric):\n    \"\"\"Metric M_new, which represents the percentage of novel class instances misclassified as known.\n\n    Parameters\n    ----------\n    known_classes : list of int\n        List of known labels, the labels the algorithm knows prior to the online phase\n    cm : ConfusionMatrixNovelty\n        Optional, can specify an already existing confusion matrix instead of creating a new one for the metric\n\n    Attributes\n    ----------\n    cm : ConfusionMatrixNovelty\n        Confusion matrix\n    \"\"\"\n    def __init__(self, known_classes, cm: ConfusionMatrixNovelty = None):\n        if cm is None:\n            cm = ConfusionMatrixNovelty(known_classes)\n\n        super(metrics.base.MultiClassMetric, self).__init__(cm)\n\n    def get(self):\n        fn = self.cm.false_negatives_novelty() #Number of novelties wrongly classified as known\n\n        try:\n            return fn / self.cm.nc_samples\n        except ZeroDivisionError:\n            return 0.0\n</code></pre>"},{"location":"reference/metrics/ttd/","title":"ttd","text":""},{"location":"reference/metrics/ttd/#streamndr.metrics.ttd.TTD","title":"<code>TTD</code>","text":"<p>             Bases: <code>MultiClassMetric</code></p> <p>Time To Detection (TTD), represents the amount of samples needed for a novel class to be classified as a novel concept, as defined in [1].</p> <p>[1] Gaudreault, JG., Branco, P. (2023). Toward Streamlining the Evaluation of Novelty Detection in Data Streams.      In: Bifet, A., Lorena, A.C., Ribeiro, R.P., Gama, J., Abreu, P.H. (eds) Discovery Science. DS 2023. Lecture Notes in Computer Science(), vol 14276. Springer, Cham. </p> <p>Parameters:</p> Name Type Description Default <code>known_classes</code> <code>list of int</code> <p>List of known labels, the labels the algorithm knows prior to the online phase</p> required <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Optional, can specify an already existing confusion matrix instead of creating a new one for the metric</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>cm</code> <code>ConfusionMatrixNovelty</code> <p>Confusion matrix</p> Source code in <code>streamndr/metrics/ttd.py</code> <pre><code>class TTD(metrics.base.MultiClassMetric):\n    \"\"\"Time To Detection (TTD), represents the amount of samples needed for a novel class to be classified as a novel concept, as defined in [1].\n\n    [1] Gaudreault, JG., Branco, P. (2023). Toward Streamlining the Evaluation of Novelty Detection in Data Streams. \n        In: Bifet, A., Lorena, A.C., Ribeiro, R.P., Gama, J., Abreu, P.H. (eds) Discovery Science. DS 2023. Lecture Notes in Computer Science(), vol 14276. Springer, Cham. \n\n    Parameters\n    ----------\n    known_classes : list of int\n        List of known labels, the labels the algorithm knows prior to the online phase\n    cm : ConfusionMatrixNovelty\n        Optional, can specify an already existing confusion matrix instead of creating a new one for the metric\n\n    Attributes\n    ----------\n    cm : ConfusionMatrixNovelty\n        Confusion matrix\n    \"\"\"\n    def __init__(self, known_classes, cm: ConfusionMatrixNovelty = None):\n        if cm is None:\n            cm = ConfusionMatrixNovelty(known_classes)\n\n        super(metrics.base.MultiClassMetric, self).__init__(cm)\n\n        self.time_since_first_seen = dict()\n        self.time_to_detection = dict()\n\n    def update(self, y_true, y_pred, sample_weight=1.0):\n        super().update(y_true, y_pred, sample_weight)\n\n        if (not y_true in self.time_since_first_seen) and (not y_true in self.cm._init_classes):\n            self.time_since_first_seen[y_true] = 0\n\n        elif (y_true in self.time_since_first_seen) and (not y_true in self.time_to_detection) and (not y_pred in self.cm._init_classes.union({-1})):\n            self.time_to_detection[y_true] = self.time_since_first_seen[y_true]\n\n        elif (y_true in self.time_since_first_seen) and (not y_true in self.time_to_detection) and (y_pred in self.cm._init_classes.union({-1})):\n            self.time_since_first_seen[y_true] += 1\n\n        return self\n\n    def get(self):\n        tmp = dict()\n\n        for key in self.time_since_first_seen:\n            if key in self.time_to_detection:\n                tmp[key] = self.time_to_detection[key]\n            else:\n                tmp[key] = -1\n\n        return tmp\n\n    def __repr__(self):\n        return \"TTD: \" + pprint.pformat(self.get())\n</code></pre>"},{"location":"reference/model/ecsminerwf/","title":"ecsminerwf","text":""},{"location":"reference/model/ecsminerwf/#streamndr.model.ecsminerwf.ECSMinerWF","title":"<code>ECSMinerWF</code>","text":"<p>             Bases: <code>MiniBatchClassifier</code></p> <p>Implementation of the ECSMinerWF (ECSMiner without feedback) algorithm for novelty detection.</p> <p>Parameters:</p> Name Type Description Default <code>K</code> <code>int</code> <p>Number of pseudopoints per classifier. In other words, it is the number of K cluster for the clustering algorithm.</p> <code>50</code> <code>min_examples_cluster</code> <code>int</code> <p>Minimum number of examples to declare a novel class</p> <code>50</code> <code>ensemble_size</code> <code>int</code> <p>Number of classifiers to use to create the ensemble</p> <code>6</code> <code>verbose</code> <code>int</code> <p>Controls the level of verbosity, the higher, the more messages are displayed. Can be '1', '2', or '3'.</p> <code>0</code> <code>random_state</code> <code>int</code> <p>Seed for the random number generation. Makes the algorithm deterministic if a number is provided.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>MAX_MEMORY_SIZE</code> <code>int</code> <p>Constant used to determine the maximum number of rows used by numpy for the computation of the closest clusters. A higher number is faster but takes more memory.</p> <code>models</code> <code>list of list of MicroCluster</code> <p>List containing the models created in the offline phase. In other words, it contains multiple lists of MicroClusters.</p> <code>novel_models</code> <code>list of MicroCluster</code> <p>Contains the clusters representing novel classes, added during the online phase</p> <code>nb_class_unknown</code> <code>dict</code> <p>Tracks the number of samples of each true class value currently in the unknown buffer (short_mem). Used to compute the unknown rate.</p> <code>class_sample_counter</code> <code>dict</code> <p>Tracks the total number of samples of each true class value seen in the stream. Used to compute the unknown rate.</p> <code>sample_counter</code> <code>int</code> <p>Number of samples treated, used by the forgetting mechanism</p> <code>short_mem</code> <code>list of ShortMemInstance</code> <p>Buffer memory containing the samples labeled as unknown temporarily for the novelty detection process</p> <code>last_nd</code> <code>int</code> <p>Timestamp when the last novelty detection was performed. Used to determine if a new novelty detection should be performed.</p> <code>before_offline_phase</code> <code>bool</code> <p>Whether or not the algorithm was initialized (offline phase). The algorithm needs to first be initialized to be used in an online fashion.</p> Source code in <code>streamndr/model/ecsminerwf.py</code> <pre><code>class ECSMinerWF(base.MiniBatchClassifier):\n    \"\"\"Implementation of the ECSMinerWF (ECSMiner without feedback) algorithm for novelty detection.\n\n    Parameters\n    ----------\n    K : int\n        Number of pseudopoints per classifier. In other words, it is the number of K cluster for the clustering algorithm.\n    min_examples_cluster : int\n        Minimum number of examples to declare a novel class \n    ensemble_size : int\n        Number of classifiers to use to create the ensemble\n    verbose : int\n        Controls the level of verbosity, the higher, the more messages are displayed. Can be '1', '2', or '3'.\n    random_state : int\n        Seed for the random number generation. Makes the algorithm deterministic if a number is provided.\n\n    Attributes\n    ----------\n    MAX_MEMORY_SIZE : int\n        Constant used to determine the maximum number of rows used by numpy for the computation of the closest clusters. A higher number is faster but takes more memory.\n    models : list of list of MicroCluster\n        List containing the models created in the offline phase. In other words, it contains multiple lists of MicroClusters.\n    novel_models : list of MicroCluster\n        Contains the clusters representing novel classes, added during the online phase\n    nb_class_unknown : dict\n        Tracks the number of samples of each true class value currently in the unknown buffer (short_mem). Used to compute the unknown rate.\n    class_sample_counter : dict\n        Tracks the total number of samples of each true class value seen in the stream. Used to compute the unknown rate.\n    sample_counter : int\n        Number of samples treated, used by the forgetting mechanism\n    short_mem : list of ShortMemInstance\n        Buffer memory containing the samples labeled as unknown temporarily for the novelty detection process\n    last_nd : int\n        Timestamp when the last novelty detection was performed. Used to determine if a new novelty detection should be performed.\n    before_offline_phase : bool\n        Whether or not the algorithm was initialized (offline phase). The algorithm needs to first be initialized to be used in an online fashion.\n    \"\"\"\n\n    MAX_MEMORY_SIZE = 50000\n\n    def __init__(self,\n                 K=50, \n                 min_examples_cluster=50, #Number of instances requried to declare a novel class \n                 ensemble_size=6, \n                 verbose=0,\n                 random_state=None):\n\n        super().__init__()\n        self.K = K\n        self.min_examples_cluster = min_examples_cluster\n        self.ensemble_size = ensemble_size\n        self.verbose = verbose\n        self.random_state = random_state\n\n        self.models = []\n        self.novel_models = []\n        self.nb_class_unknown = dict()\n        self.class_sample_counter = dict()\n        self.sample_counter = 0\n        self.short_mem = [] #Potential novel class instances\n        self.last_nd = -self.min_examples_cluster #No novelty detection performed yet\n        self.before_offline_phase = True\n\n    def learn_one(self, x, y, w=1.0):\n        #Function used by river algorithms to learn one sample. It is not applicable to this algorithm since the offline phase requires all samples\n        #to arrive at once. It is only added as to follow River's API.\n        pass\n\n\n    def learn_many(self, X, y, w=1.0):\n        \"\"\"Represents the offline phase of the algorithm. Receives a number of samples and their given labels and learns all of the known classes.\n\n        Parameters\n        ----------\n        X : pandas.DataFrame or numpy.ndarray\n            Samples to be learned by the model\n        y : list of int\n            Labels corresponding to the given samples, must be the same length as the number of samples\n        w : float, optional\n            Weights, not used, by default 1.0\n\n        Returns\n        -------\n        ECSMinerWF\n            Itself\n        \"\"\"\n        if isinstance(X, pd.DataFrame):\n            X = X.to_numpy()\n\n        self.chunk_size = math.ceil(len(X)/self.ensemble_size)\n\n        # in offline phase, consider all instances arriving at the same time in the microclusters:\n        timestamp = len(X)\n\n        #Separate data into (ensemble_size) chunks\n        for i in range(0, self.ensemble_size):\n            X_chunk = X[i:i+self.chunk_size]\n            y_chunk = y[i:i+self.chunk_size]\n\n            self.models.append(self._generate_microclusters(X_chunk, y_chunk, timestamp, self.K, min_samples=3)) #As per ECSMiner paper, any microcluster with less than 3 instances is discarded\n\n        self.before_offline_phase = False\n\n        return self\n\n    def predict_one(self, X, y=None):\n        \"\"\"Represents the online phase. Equivalent to predict_many() with only one sample. Receives only one sample, predict its label and adds \n        it to the cluster if it is a known class. Otherwise, if it's unknown, it is added to the short term memory and novelty detection is \n        performed once the trigger has been reached (min_examples_cluster).\n\n        Parameters\n        ----------\n        X : dict\n            Sample\n        y : int\n            True y value of the sample, if available. Only used for metric evaluation (UnkRate).\n\n        Returns\n        -------\n        numpy.ndarray\n            Label predicted for the given sample, predicts -1 if labeled as unknown\n        \"\"\"\n        return self.predict_many(np.array(list(X.values()))[None,:], [y])\n\n\n    def predict_many(self, X, y=None):\n        \"\"\"Represents the online phase. Receives multiple samples, for each sample predict its label and adds it to the cluster if it is a known class. \n        Otherwise, if it's unknown, it is added to the short term memory and novelty detection is performed once the trigger has been reached (min_examples_cluster).\n\n        Parameters\n        ----------\n        X : pandas.DataFrame or numpy.ndarray\n            Samples\n        y : list of int\n            True y values of the samples, if available. Only used for metric evaluation (UnkRate).\n\n        Returns\n        -------\n        numpy.ndarray\n            Array of length len(X) containing the predicted labels, predicts -1 if the corresponding sample labeled as unknown\n\n        Raises\n        ------\n        Exception\n            If the model has not been trained first with learn_many() (offline phase)\n        \"\"\"\n        if self.before_offline_phase:\n            raise Exception(\"Model must be fitted first\")\n\n        if isinstance(X, pd.DataFrame):\n            X = X.to_numpy() #Converting DataFrame to numpy array\n\n        closest_model_cluster, y_preds = self._majority_voting(X)\n\n        if len(self.novel_models) &gt; 0: #We have novel clusters in our list\n            novel_closest_clusters, _ = self._get_closest_clusters(X, [microcluster.centroid for microcluster in self.novel_models])\n\n        pred_label = []\n        for i in range(len(X)):\n            self.sample_counter += 1\n            if y is not None:\n                if y[i] not in self.class_sample_counter:\n                    self.class_sample_counter[y[i]] = 1\n                else:\n                    self.class_sample_counter[y[i]] += 1\n\n            closest_cluster = self.models[closest_model_cluster[i][0]][closest_model_cluster[i][1]]\n\n            self._filter_buffer()\n\n            if closest_cluster.distance_to_centroid(X[i]) &lt;= closest_cluster.max_distance: # classify with the label from majority voting\n                pred_label.append(y_preds[i])\n                closest_cluster.update_cluster(X[i], self.sample_counter, False)\n\n            elif (len(self.novel_models) &gt; 0) and (self.novel_models[novel_closest_clusters[i]].distance_to_centroid(X[i]) &lt;= closest_cluster.max_distance): #One of our novel cluster can explain our sample\n                pred_label.append(self.novel_models[novel_closest_clusters[i]].label)\n                self.novel_models[novel_closest_clusters[i]].update_cluster(X[i], self.sample_counter, False)\n\n            else: #Classify as unknown\n                pred_label.append(-1)\n\n                if y is not None:\n                    self.short_mem.append(ShortMemInstance(X[i], self.sample_counter, y[i]))\n                    if y[i] not in self.nb_class_unknown:\n                        self.nb_class_unknown[y[i]] = 1\n                    else:\n                        self.nb_class_unknown[y[i]] += 1\n                else:\n                    self.short_mem.append(ShortMemInstance(X[i], self.sample_counter))\n\n                if len(self.short_mem) &gt; self.min_examples_cluster and (self.last_nd + self.min_examples_cluster) &lt;= self.sample_counter:\n                    self.last_nd = self.sample_counter\n\n                    novel_clusters = self._novelty_detect()\n\n                    if novel_clusters is not None: #We have novelty clusters\n                        for novel_cluster in novel_clusters:\n                            max_label_ensemble = max([cluster.label for model in self.models for cluster in model])\n\n                            max_label_novel = max([cluster.label for cluster in self.novel_models]) if len(self.novel_models) &gt; 0 else -1\n\n                            novel_cluster.label = max(max_label_ensemble, max_label_novel) + 1\n\n                            if self.verbose &gt; 0: print(\"Novel cluster detected: \", novel_cluster.small_str())\n\n                            #Add novel cluster to our novel models list\n                            self.novel_models.append(novel_cluster)\n\n                            #Remove instances from the buffer\n                            for instance in novel_cluster.instances:\n                                index = self.short_mem.index(instance)\n                                y_true = self.short_mem[index].y_true\n                                if y_true is not None:\n                                    self.nb_class_unknown[y_true] -= 1\n                                self.short_mem.pop(index)\n\n        return np.array(pred_label)\n\n    def get_unknown_rate(self):\n        \"\"\"Returns the unknown rate, represents the percentage of unknown samples on the total number of samples classified in the online phase.\n\n        Returns\n        -------\n        float\n            Unknown rate\n        \"\"\"\n        return len(self.short_mem) / self.sample_counter\n\n    def get_class_unknown_rate(self):\n        \"\"\"Returns the unknown rate per class. Represents the percentage of unknown samples on the total number of samples of that class seen during the stream.\n\n        Returns\n        -------\n        dict\n            Dictionary containing the unknown rate of each class\n        \"\"\"\n        return {key: val / self.class_sample_counter[key] for key, val in self.nb_class_unknown.items()}\n\n    def predict_proba_one(self,X):\n        #Function used by river algorithms to get the probability of the prediction. It is not applicable to this algorithm since it only predicts labels. \n        #It is only added as to follow River's API.\n        pass\n\n    def predict_proba_many(self, X):\n        #Function used by river algorithms to get the probability of the predictions. It is not applicable to this algorithm since it only predicts labels. \n        #It is only added as to follow River's API.\n        pass\n\n    def _generate_microclusters(self, X, y, timestamp, K, keep_instances=False, min_samples=0):\n        clf = KMeans(n_clusters=K, random_state=self.random_state).fit(X)\n        labels = clf.labels_\n\n        microclusters = []\n        for microcluster in np.unique(labels):\n            cluster_instances = X[labels == microcluster]\n            y_cluster_instances = y[labels == microcluster]\n\n            values, counts = np.unique(y_cluster_instances, return_counts=True)\n            most_common_y = values[np.argmax(counts)]\n\n            if len(cluster_instances) &gt;= min_samples:\n                mc = MicroCluster(most_common_y, instances=cluster_instances, timestamp=timestamp, keep_instances=keep_instances)\n                microclusters.append(mc)\n\n        return microclusters\n\n    def _majority_voting(self, X):\n        closest_clusters = []\n        labels = []\n        dists = []\n\n        for model in self.models:\n            closest_clusters_model, dist = self._get_closest_clusters(X, [microcluster.centroid for microcluster in model])\n            closest_clusters.append(closest_clusters_model)\n            labels.append([model[closest_cluster].label for closest_cluster in closest_clusters_model])\n            dists.append(dist) \n\n        best_models = np.argmin(dists, axis=0)\n\n        closest_model_cluster = []\n        for i in range(len(X)):\n            closest_model_cluster.append((best_models[i], closest_clusters[best_models[i]][i]))\n\n        return closest_model_cluster, [Counter(col).most_common(1)[0][0] for col in zip(*labels)]\n\n\n    def _get_closest_clusters(self, X, centroids):   \n\n        if len(centroids) == 0:\n            print(\"No clusters\")\n            return\n\n        centroids = np.array(centroids)\n        norm_dists = np.zeros((X.shape[0],centroids.shape[0]))\n\n        # Cut into batches if there are too many samples to save on memory\n        for idx in range(math.ceil(X.shape[0]/ECSMinerWF.MAX_MEMORY_SIZE)):\n            sl = slice(idx*ECSMinerWF.MAX_MEMORY_SIZE, (idx+1)*ECSMinerWF.MAX_MEMORY_SIZE)\n            norm_dists[sl] = np.linalg.norm(np.subtract(X[sl, :, None], np.transpose(centroids)), axis=1)\n\n        return np.argmin(norm_dists, axis=1), np.amin(norm_dists, axis=1)\n\n    def _novelty_detect(self):\n        if self.verbose &gt; 0: print(\"Novelty detection started\")\n\n        X = np.array([instance.point for instance in self.short_mem])\n        new_class_vote = 0\n\n        #Creating F-pseudopoints\n        K0 = math.ceil(self.K * (len(X) / self.chunk_size))\n        K0 = max(K0, self.K)\n\n        f_microclusters = self._generate_microclusters(X, np.array([-1] * len(X)), self.sample_counter, K0, keep_instances=True)\n        f_microclusters_centroids = np.array([cl.centroid for cl in f_microclusters])\n\n        potential_novel_clusters_idx = []\n        #Computing qNSC for each model in our ensemble\n        for model in self.models:\n            qnscs = self._qnsc(f_microclusters_centroids, model)\n\n            potential_clusters = []\n            total_instances = 0\n            for i, f_microcluster in enumerate(f_microclusters):\n                if qnscs[i] &gt; 0:\n                    potential_clusters.append(f_microcluster)\n                    total_instances += f_microcluster.n\n                    potential_novel_clusters_idx.append(i)\n\n            if total_instances &gt; self.min_examples_cluster: new_class_vote += 1\n\n\n        if new_class_vote == len(self.models):\n            #Get the indices of all clusters which had a positive qnsc for all models\n            novel_clusters_idx = [item for item, count in Counter(potential_novel_clusters_idx).items() if count == len(self.models)]\n            novel_clusters = [f_microclusters[i] for i in novel_clusters_idx]\n\n            return novel_clusters\n\n        else:\n            return None\n\n\n    def _qnsc(self, pseudopoints, model):\n        #Calculate mean distance of all points between themselves\n        dists = np.linalg.norm(pseudopoints - pseudopoints[:,None], axis=-1)\n        dists[np.arange(dists.shape[0]), np.arange(dists.shape[0])] = np.nan\n        mean_distances_between_points = np.nanmean(dists, axis=0)\n\n        #Calculate minimum distance between points known cluster\n        all_centroids = [microcluster.centroid for microcluster in model]\n        _, minimum_distances_to_class = self._get_closest_clusters(pseudopoints, all_centroids)\n\n        qnscs = (minimum_distances_to_class - mean_distances_between_points) / np.maximum(minimum_distances_to_class, mean_distances_between_points)\n\n        return qnscs\n\n    def _filter_buffer(self):\n        for instance in self.short_mem:\n            if (self.sample_counter - instance.timestamp &gt; self.chunk_size): #We remove samples that have an age greater than the chunk size\n                index = self.short_mem.index(instance)\n                y_true = self.short_mem[index].y_true\n                if y_true is not None:\n                    self.nb_class_unknown[y_true] -= 1\n                self.short_mem.pop(index)\n            else: #No need to iterate over the whole buffer since older elements are at the beginning\n                break;\n</code></pre>"},{"location":"reference/model/ecsminerwf/#streamndr.model.ecsminerwf.ECSMinerWF.get_class_unknown_rate","title":"<code>get_class_unknown_rate()</code>","text":"<p>Returns the unknown rate per class. Represents the percentage of unknown samples on the total number of samples of that class seen during the stream.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the unknown rate of each class</p> Source code in <code>streamndr/model/ecsminerwf.py</code> <pre><code>def get_class_unknown_rate(self):\n    \"\"\"Returns the unknown rate per class. Represents the percentage of unknown samples on the total number of samples of that class seen during the stream.\n\n    Returns\n    -------\n    dict\n        Dictionary containing the unknown rate of each class\n    \"\"\"\n    return {key: val / self.class_sample_counter[key] for key, val in self.nb_class_unknown.items()}\n</code></pre>"},{"location":"reference/model/ecsminerwf/#streamndr.model.ecsminerwf.ECSMinerWF.get_unknown_rate","title":"<code>get_unknown_rate()</code>","text":"<p>Returns the unknown rate, represents the percentage of unknown samples on the total number of samples classified in the online phase.</p> <p>Returns:</p> Type Description <code>float</code> <p>Unknown rate</p> Source code in <code>streamndr/model/ecsminerwf.py</code> <pre><code>def get_unknown_rate(self):\n    \"\"\"Returns the unknown rate, represents the percentage of unknown samples on the total number of samples classified in the online phase.\n\n    Returns\n    -------\n    float\n        Unknown rate\n    \"\"\"\n    return len(self.short_mem) / self.sample_counter\n</code></pre>"},{"location":"reference/model/ecsminerwf/#streamndr.model.ecsminerwf.ECSMinerWF.learn_many","title":"<code>learn_many(X, y, w=1.0)</code>","text":"<p>Represents the offline phase of the algorithm. Receives a number of samples and their given labels and learns all of the known classes.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame or ndarray</code> <p>Samples to be learned by the model</p> required <code>y</code> <code>list of int</code> <p>Labels corresponding to the given samples, must be the same length as the number of samples</p> required <code>w</code> <code>float</code> <p>Weights, not used, by default 1.0</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ECSMinerWF</code> <p>Itself</p> Source code in <code>streamndr/model/ecsminerwf.py</code> <pre><code>def learn_many(self, X, y, w=1.0):\n    \"\"\"Represents the offline phase of the algorithm. Receives a number of samples and their given labels and learns all of the known classes.\n\n    Parameters\n    ----------\n    X : pandas.DataFrame or numpy.ndarray\n        Samples to be learned by the model\n    y : list of int\n        Labels corresponding to the given samples, must be the same length as the number of samples\n    w : float, optional\n        Weights, not used, by default 1.0\n\n    Returns\n    -------\n    ECSMinerWF\n        Itself\n    \"\"\"\n    if isinstance(X, pd.DataFrame):\n        X = X.to_numpy()\n\n    self.chunk_size = math.ceil(len(X)/self.ensemble_size)\n\n    # in offline phase, consider all instances arriving at the same time in the microclusters:\n    timestamp = len(X)\n\n    #Separate data into (ensemble_size) chunks\n    for i in range(0, self.ensemble_size):\n        X_chunk = X[i:i+self.chunk_size]\n        y_chunk = y[i:i+self.chunk_size]\n\n        self.models.append(self._generate_microclusters(X_chunk, y_chunk, timestamp, self.K, min_samples=3)) #As per ECSMiner paper, any microcluster with less than 3 instances is discarded\n\n    self.before_offline_phase = False\n\n    return self\n</code></pre>"},{"location":"reference/model/ecsminerwf/#streamndr.model.ecsminerwf.ECSMinerWF.predict_many","title":"<code>predict_many(X, y=None)</code>","text":"<p>Represents the online phase. Receives multiple samples, for each sample predict its label and adds it to the cluster if it is a known class.  Otherwise, if it's unknown, it is added to the short term memory and novelty detection is performed once the trigger has been reached (min_examples_cluster).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame or ndarray</code> <p>Samples</p> required <code>y</code> <code>list of int</code> <p>True y values of the samples, if available. Only used for metric evaluation (UnkRate).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of length len(X) containing the predicted labels, predicts -1 if the corresponding sample labeled as unknown</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the model has not been trained first with learn_many() (offline phase)</p> Source code in <code>streamndr/model/ecsminerwf.py</code> <pre><code>def predict_many(self, X, y=None):\n    \"\"\"Represents the online phase. Receives multiple samples, for each sample predict its label and adds it to the cluster if it is a known class. \n    Otherwise, if it's unknown, it is added to the short term memory and novelty detection is performed once the trigger has been reached (min_examples_cluster).\n\n    Parameters\n    ----------\n    X : pandas.DataFrame or numpy.ndarray\n        Samples\n    y : list of int\n        True y values of the samples, if available. Only used for metric evaluation (UnkRate).\n\n    Returns\n    -------\n    numpy.ndarray\n        Array of length len(X) containing the predicted labels, predicts -1 if the corresponding sample labeled as unknown\n\n    Raises\n    ------\n    Exception\n        If the model has not been trained first with learn_many() (offline phase)\n    \"\"\"\n    if self.before_offline_phase:\n        raise Exception(\"Model must be fitted first\")\n\n    if isinstance(X, pd.DataFrame):\n        X = X.to_numpy() #Converting DataFrame to numpy array\n\n    closest_model_cluster, y_preds = self._majority_voting(X)\n\n    if len(self.novel_models) &gt; 0: #We have novel clusters in our list\n        novel_closest_clusters, _ = self._get_closest_clusters(X, [microcluster.centroid for microcluster in self.novel_models])\n\n    pred_label = []\n    for i in range(len(X)):\n        self.sample_counter += 1\n        if y is not None:\n            if y[i] not in self.class_sample_counter:\n                self.class_sample_counter[y[i]] = 1\n            else:\n                self.class_sample_counter[y[i]] += 1\n\n        closest_cluster = self.models[closest_model_cluster[i][0]][closest_model_cluster[i][1]]\n\n        self._filter_buffer()\n\n        if closest_cluster.distance_to_centroid(X[i]) &lt;= closest_cluster.max_distance: # classify with the label from majority voting\n            pred_label.append(y_preds[i])\n            closest_cluster.update_cluster(X[i], self.sample_counter, False)\n\n        elif (len(self.novel_models) &gt; 0) and (self.novel_models[novel_closest_clusters[i]].distance_to_centroid(X[i]) &lt;= closest_cluster.max_distance): #One of our novel cluster can explain our sample\n            pred_label.append(self.novel_models[novel_closest_clusters[i]].label)\n            self.novel_models[novel_closest_clusters[i]].update_cluster(X[i], self.sample_counter, False)\n\n        else: #Classify as unknown\n            pred_label.append(-1)\n\n            if y is not None:\n                self.short_mem.append(ShortMemInstance(X[i], self.sample_counter, y[i]))\n                if y[i] not in self.nb_class_unknown:\n                    self.nb_class_unknown[y[i]] = 1\n                else:\n                    self.nb_class_unknown[y[i]] += 1\n            else:\n                self.short_mem.append(ShortMemInstance(X[i], self.sample_counter))\n\n            if len(self.short_mem) &gt; self.min_examples_cluster and (self.last_nd + self.min_examples_cluster) &lt;= self.sample_counter:\n                self.last_nd = self.sample_counter\n\n                novel_clusters = self._novelty_detect()\n\n                if novel_clusters is not None: #We have novelty clusters\n                    for novel_cluster in novel_clusters:\n                        max_label_ensemble = max([cluster.label for model in self.models for cluster in model])\n\n                        max_label_novel = max([cluster.label for cluster in self.novel_models]) if len(self.novel_models) &gt; 0 else -1\n\n                        novel_cluster.label = max(max_label_ensemble, max_label_novel) + 1\n\n                        if self.verbose &gt; 0: print(\"Novel cluster detected: \", novel_cluster.small_str())\n\n                        #Add novel cluster to our novel models list\n                        self.novel_models.append(novel_cluster)\n\n                        #Remove instances from the buffer\n                        for instance in novel_cluster.instances:\n                            index = self.short_mem.index(instance)\n                            y_true = self.short_mem[index].y_true\n                            if y_true is not None:\n                                self.nb_class_unknown[y_true] -= 1\n                            self.short_mem.pop(index)\n\n    return np.array(pred_label)\n</code></pre>"},{"location":"reference/model/ecsminerwf/#streamndr.model.ecsminerwf.ECSMinerWF.predict_one","title":"<code>predict_one(X, y=None)</code>","text":"<p>Represents the online phase. Equivalent to predict_many() with only one sample. Receives only one sample, predict its label and adds  it to the cluster if it is a known class. Otherwise, if it's unknown, it is added to the short term memory and novelty detection is  performed once the trigger has been reached (min_examples_cluster).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>dict</code> <p>Sample</p> required <code>y</code> <code>int</code> <p>True y value of the sample, if available. Only used for metric evaluation (UnkRate).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Label predicted for the given sample, predicts -1 if labeled as unknown</p> Source code in <code>streamndr/model/ecsminerwf.py</code> <pre><code>def predict_one(self, X, y=None):\n    \"\"\"Represents the online phase. Equivalent to predict_many() with only one sample. Receives only one sample, predict its label and adds \n    it to the cluster if it is a known class. Otherwise, if it's unknown, it is added to the short term memory and novelty detection is \n    performed once the trigger has been reached (min_examples_cluster).\n\n    Parameters\n    ----------\n    X : dict\n        Sample\n    y : int\n        True y value of the sample, if available. Only used for metric evaluation (UnkRate).\n\n    Returns\n    -------\n    numpy.ndarray\n        Label predicted for the given sample, predicts -1 if labeled as unknown\n    \"\"\"\n    return self.predict_many(np.array(list(X.values()))[None,:], [y])\n</code></pre>"},{"location":"reference/model/minas/","title":"minas","text":""},{"location":"reference/model/minas/#streamndr.model.minas.Minas","title":"<code>Minas</code>","text":"<p>             Bases: <code>MiniBatchClassifier</code></p> <p>Implementation of the MINAS algorithm for novelty detection.</p> <p>Parameters:</p> Name Type Description Default <code>kini</code> <code>int</code> <p>Number of K clusters for the clustering (KMeans or Clustream) algorithm</p> <code>3</code> <code>cluster_algorithm</code> <code>str</code> <p>String containing the clustering algorithm to use, supports 'kmeans' and 'clustream'</p> <code>'kmeans'</code> <code>random_state</code> <code>int</code> <p>Seed for the random number generation. Makes the algorithm deterministic if a number is provided.</p> <code>None</code> <code>min_short_mem_trigger</code> <code>int</code> <p>Minimum number of samples in the short term memory to trigger the novelty detection process</p> <code>10</code> <code>min_examples_cluster</code> <code>int</code> <p>Minimum number of samples to from a cluster</p> <code>10</code> <code>threshold_strategy</code> <code>int</code> <p>Strategy to use to compute the threshold. Can be '1', '2', or '3' as described in the MINAS paper.</p> <code>1</code> <code>threshold_factor</code> <code>float</code> <p>Factor for the threshold computation</p> <code>1.1</code> <code>window_size</code> <code>int</code> <p>Number of samples used by the forgetting mechanism</p> <code>100</code> <code>update_summary</code> <code>bool</code> <p>Whether or not the microcluster's properties are updated when a new point is added to it</p> <code>False</code> <code>verbose</code> <code>int</code> <p>Controls the level of verbosity, the higher, the more messages are displayed. Can be '1', '2', or '3'.</p> <code>0</code> <p>Attributes:</p> Name Type Description <code>MAX_MEMORY_SIZE</code> <code>int</code> <p>Constant used to determine the maximum number of rows used by numpy for the computation of the closest clusters. A higher number is faster but takes more memory.</p> <code>before_offline_phase</code> <code>bool</code> <p>Whether or not the algorithm was initialized (offline phase). The algorithm needs to first be initialized to be used in an online fashion.</p> <code>short_mem</code> <code>list of ShortMemInstance</code> <p>Buffer memory containing the samples labeled as unknown temporarily for the novelty detection process</p> <code>sleep_mem</code> <code>list of MicroCluster</code> <p>Microclusters that have not have any new points added from the strem for a period of time are temporarily moved to a sleep memory</p> <code>nb_class_unknown</code> <code>dict</code> <p>Tracks the number of samples of each true class value currently in the unknown buffer (short_mem). Used to compute the unknown rate.</p> <code>class_sample_counter</code> <code>dict</code> <p>Tracks the total number of samples of each true class value seen in the stream. Used to compute the unknown rate.</p> <code>sample_counter</code> <code>int</code> <p>Number of samples treated, used by the forgetting mechanism</p> Source code in <code>streamndr/model/minas.py</code> <pre><code>class Minas(base.MiniBatchClassifier):\n    \"\"\"Implementation of the MINAS algorithm for novelty detection.\n\n    Parameters\n    ----------\n    kini : int\n        Number of K clusters for the clustering (KMeans or Clustream) algorithm\n    cluster_algorithm : str\n        String containing the clustering algorithm to use, supports 'kmeans' and 'clustream'\n    random_state : int\n        Seed for the random number generation. Makes the algorithm deterministic if a number is provided.\n    min_short_mem_trigger : int\n        Minimum number of samples in the short term memory to trigger the novelty detection process\n    min_examples_cluster : int\n        Minimum number of samples to from a cluster\n    threshold_strategy : int\n        Strategy to use to compute the threshold. Can be '1', '2', or '3' as described in the MINAS paper.\n    threshold_factor : float\n        Factor for the threshold computation\n    window_size : int\n        Number of samples used by the forgetting mechanism\n    update_summary : bool\n        Whether or not the microcluster's properties are updated when a new point is added to it\n    verbose : int\n        Controls the level of verbosity, the higher, the more messages are displayed. Can be '1', '2', or '3'.\n\n    Attributes\n    ----------\n    MAX_MEMORY_SIZE : int\n        Constant used to determine the maximum number of rows used by numpy for the computation of the closest clusters. A higher number is faster but takes more memory.\n    before_offline_phase : bool\n        Whether or not the algorithm was initialized (offline phase). The algorithm needs to first be initialized to be used in an online fashion.\n    short_mem : list of ShortMemInstance\n        Buffer memory containing the samples labeled as unknown temporarily for the novelty detection process\n    sleep_mem : list of MicroCluster\n        Microclusters that have not have any new points added from the strem for a period of time are temporarily moved to a sleep memory\n    nb_class_unknown : dict\n        Tracks the number of samples of each true class value currently in the unknown buffer (short_mem). Used to compute the unknown rate.\n    class_sample_counter : dict\n        Tracks the total number of samples of each true class value seen in the stream. Used to compute the unknown rate.\n    sample_counter : int\n        Number of samples treated, used by the forgetting mechanism\n    \"\"\"\n\n\n    MAX_MEMORY_SIZE = 50000\n\n    def __init__(self,\n                 kini=3,\n                 cluster_algorithm='kmeans',\n                 random_state=None,\n                 min_short_mem_trigger=10,\n                 min_examples_cluster=10,\n                 threshold_strategy=1,\n                 threshold_factor=1.1,\n                 window_size=100,\n                 update_summary=False,\n                 verbose=0):\n        super().__init__()\n        self.kini = kini\n        self.random_state = random_state\n\n        accepted_algos = ['kmeans','clustream']\n        if cluster_algorithm not in accepted_algos:\n            print('Available algorithms: {}'.format(', '.join(accepted_algos)))\n        else:\n            self.cluster_algorithm = cluster_algorithm\n\n        self.microclusters = []  # list of microclusters\n        self.before_offline_phase = True\n\n        self.short_mem = []\n        self.sleep_mem = []\n        self.nb_class_unknown = dict()\n        self.class_sample_counter = dict()\n        self.min_short_mem_trigger = min_short_mem_trigger\n        self.min_examples_cluster = min_examples_cluster\n        self.threshold_strategy = threshold_strategy\n        self.threshold_factor = threshold_factor\n        self.window_size = window_size\n        self.update_summary = update_summary\n        self.verbose = verbose\n        self.sample_counter = 0  # to be used with window_size\n\n    def learn_one(self, x, y, w=1.0):\n        \"\"\"Function used by river algorithms to learn one sample. It is not applicable to this algorithm since the offline phase requires all samples\n        to arrive at once. It is only added as to follow River's API.\n\n        Parameters\n        ----------\n        x : dict\n            Sample\n        y : int\n            Label of the given sample\n        w : float, optional\n            Weight, not used, by default 1.0\n        \"\"\"\n        # Not applicable\n        pass\n\n\n    def learn_many(self, X, y, w=1.0):\n        \"\"\"Represents the offline phase of the algorithm. Receives a number of samples and their given labels and learns all of the known classes.\n\n        Parameters\n        ----------\n        X : pandas.DataFrame or numpy.ndarray\n            Samples to be learned by the model\n        y : list of int\n            Labels corresponding to the given samples, must be the same length as the number of samples\n        w : float, optional\n            Weights, not used, by default 1.0\n\n        Returns\n        -------\n        Minas\n            Itself\n        \"\"\"\n        if isinstance(X, pd.DataFrame):\n            X = X.to_numpy()\n\n        self.microclusters = self._offline(X, y)\n        self.before_offline_phase = False\n\n        return self\n\n    def predict_one(self, X, y=None):\n        \"\"\"Represents the online phase. Equivalent to predict_many() with only one sample. Receives only one sample, predict its label and adds \n        it to the cluster if it is a known class. Otherwise, if it's unknown, it is added to the short term memory and novelty detection is \n        performed once the trigger has been reached (min_short_mem_trigger).\n\n        Parameters\n        ----------\n        X : dict\n            Sample\n        y : int\n            True y value of the sample, if available. Only used for metric evaluation (UnkRate).\n\n        Returns\n        -------\n        numpy.ndarray\n            Label predicted for the given sample, predicts -1 if labeled as unknown\n        \"\"\"\n        return self.predict_many(np.array(list(X.values()))[None,:], [y])\n\n    def predict_many(self, X, y=None):\n        \"\"\"Represents the online phase. Receives multiple samples, for each sample predict its label and adds it to the cluster if it is a known class. \n        Otherwise, if it's unknown, it is added to the short term memory and novelty detection is performed once the trigger has been reached (min_short_mem_trigger).\n\n        Parameters\n        ----------\n        X : pandas.DataFrame or numpy.ndarray\n            Samples\n        y : list of int\n            True y values of the samples, if available. Only used for metric evaluation (UnkRate).\n\n        Returns\n        -------\n        numpy.ndarray\n            Array of length len(X) containing the predicted labels, predicts -1 if the corresponding sample labeled as unknown\n\n        Raises\n        ------\n        Exception\n            If the model has not been trained first with learn_many() (offline phase)\n        \"\"\"\n        if self.before_offline_phase:\n            raise Exception(\"Model must be fitted first\")\n\n        if isinstance(X, pd.DataFrame):\n            X = X.to_numpy() #Converting DataFrame to numpy array\n\n        # Finding closest clusters for received samples\n        closest_clusters = self._get_closest_clusters(X, [microcluster.centroid for microcluster in self.microclusters])\n\n        pred_label = []\n\n        for i in range(len(closest_clusters)):\n            self.sample_counter += 1\n            if y is not None:\n                if y[i] not in self.class_sample_counter:\n                    self.class_sample_counter[y[i]] = 1\n                else:\n                    self.class_sample_counter[y[i]] += 1\n\n            closest_cluster = self.microclusters[closest_clusters[i]]\n\n            if closest_cluster.encompasses(X[i]):  # classify in this cluster\n                pred_label.append(closest_cluster.label)\n\n                closest_cluster.update_cluster(X[i], self.sample_counter, self.update_summary)\n\n            else:  # classify as unknown\n                pred_label.append(-1)\n\n                if y is not None:\n                    self.short_mem.append(ShortMemInstance(X[i], self.sample_counter, y[i]))\n                    if y[i] not in self.nb_class_unknown:\n                        self.nb_class_unknown[y[i]] = 1\n                    else:\n                        self.nb_class_unknown[y[i]] += 1\n                else:\n                    self.short_mem.append(ShortMemInstance(X[i], self.sample_counter))\n\n                if self.verbose &gt; 1:\n                    print('Memory length: ', len(self.short_mem))\n                elif self.verbose &gt; 0:\n                    if len(self.short_mem) % 100 == 0: print('Memory length: ', len(self.short_mem))\n\n                if len(self.short_mem) &gt;= self.min_short_mem_trigger:\n                    self._novelty_detect()\n\n        # forgetting mechanism\n        if self.sample_counter % self.window_size == 0:\n            self._trigger_forget()\n\n\n        return np.array(pred_label)\n\n    def get_unknown_rate(self):\n        \"\"\"Returns the unknown rate, represents the percentage of unknown samples on the total number of samples classified in the online phase.\n\n        Returns\n        -------\n        float\n            Unknown rate\n        \"\"\"\n        return len(self.short_mem) / self.sample_counter\n\n    def get_class_unknown_rate(self):\n        \"\"\"Returns the unknown rate per class. Represents the percentage of unknown samples on the total number of samples of that class seen during the stream.\n\n        Returns\n        -------\n        dict\n            Dictionary containing the unknown rate of each class\n        \"\"\"\n        return {key: val / self.class_sample_counter[key] for key, val in self.nb_class_unknown.items()}\n\n    def predict_proba_one(self,X):\n        #Function used by river algorithms to get the probability of the prediction. It is not applicable to this algorithm since it only predicts labels. \n        #It is only added as to follow River's API.\n        pass\n\n    def predict_proba_many(self, X):\n        #Function used by river algorithms to get the probability of the predictions. It is not applicable to this algorithm since it only predicts labels. \n        #It is only added as to follow River's API.\n        pass\n\n    def _offline(self, X_train, y_train):\n        microclusters = []\n        # in offline phase, consider all instances arriving at the same time in the microclusters:\n        timestamp = len(X_train)\n\n        for y_class in np.unique(y_train):\n            # subset with instances from each class\n            X_class = X_train[y_train == y_class]\n\n            if self.cluster_algorithm == 'kmeans':\n                class_cluster_clf = KMeans(n_clusters=self.kini, n_init='auto',\n                                            random_state=self.random_state)\n                class_cluster_clf.fit(X_class)\n                labels = class_cluster_clf.labels_\n\n            else:\n                class_cluster_clf = CluStream(m=self.kini)\n                class_cluster_clf.init_offline(X_class, seed=self.random_state)\n\n                cluster_centers = class_cluster_clf.get_partial_cluster_centers()\n\n                labels = self._get_closest_clusters(X_class, cluster_centers)\n\n            for class_cluster in np.unique(labels):\n                # get instances in cluster\n                cluster_instances = X_class[labels == class_cluster]\n\n                microclusters.append(\n                    MicroCluster(y_class, cluster_instances, timestamp)\n                )\n\n        return microclusters\n\n    def _novelty_detect(self):\n        if self.verbose &gt; 0: print(\"Novelty detection started\")\n        possible_clusters = []\n        X = np.array([instance.point for instance in self.short_mem])\n\n        if self.cluster_algorithm == 'kmeans':\n            cluster_clf = KMeans(n_clusters=self.kini, n_init='auto',\n                                 random_state=self.random_state)\n            cluster_clf.fit(X)\n            labels = cluster_clf.labels_\n\n        else:\n            cluster_clf = CluStream(m=self.kini)\n            cluster_clf.init_offline(X, seed=self.random_state)\n\n            cluster_centers = cluster_clf.get_partial_cluster_centers()\n\n            labels = self._get_closest_clusters(X, cluster_centers)\n\n\n\n        for cluster_label in np.unique(labels):\n            cluster_instances = X[labels == cluster_label]\n            possible_clusters.append(\n                MicroCluster(-1, cluster_instances, self.sample_counter))\n\n        for cluster in possible_clusters:\n            if cluster.is_cohesive(self.microclusters) and cluster.is_representative(self.min_examples_cluster):\n                closest_cluster = cluster.find_closest_cluster(self.microclusters)\n                closest_distance = cluster.distance_to_centroid(closest_cluster.centroid)\n\n                threshold = self._best_threshold(cluster, closest_cluster,\n                                                self.threshold_strategy)\n\n                # TODO make these ifs elifs cleaner\n                if closest_distance &lt;= threshold:  # the new microcluster is an extension\n                    if self.verbose &gt; 1:\n                            print(\"Extension of cluster: \", closest_cluster)\n                    elif self.verbose &gt; 0:\n                        print(\"Extension of cluster: \", closest_cluster.small_str())\n\n                    cluster.label = closest_cluster.label\n\n                elif self.sleep_mem:  # look in the sleep memory, if not empty\n                    closest_cluster = cluster.find_closest_cluster(self.sleep_mem)\n                    closest_distance = cluster.distance_to_centroid(closest_cluster.centroid)\n\n                    if closest_distance &lt;= threshold:  # check again: the new microcluster is an extension\n                        if self.verbose &gt; 1:\n                            print(\"Waking cluster: \", closest_cluster)\n                        elif self.verbose &gt; 0:\n                            print(\"Waking cluster: \", closest_cluster.small_str())\n\n                        cluster.label = closest_cluster.label\n                        # awake old cluster\n                        self.sleep_mem.remove(closest_cluster)\n                        closest_cluster.timestamp = self.sample_counter\n                        self.microclusters.append(closest_cluster)\n\n                    else:  # the new microcluster is a novelty pattern\n                        cluster.label = max([cluster.label for cluster in self.microclusters]) + 1\n                        if self.verbose &gt; 1:\n                            print(\"Novel cluster: \", cluster)\n                        elif self.verbose &gt; 0:\n                            print(\"Novel cluster: \", cluster.small_str())\n\n                else:  # the new microcluster is a novelty pattern\n                    cluster.label = max([cluster.label for cluster in self.microclusters]) + 1\n                    if self.verbose &gt; 1:\n                            print(\"Novel cluster: \", cluster)\n                    elif self.verbose &gt; 0:\n                        print(\"Novel cluster: \", cluster.small_str())\n\n                # add the new cluster to the model\n                self.microclusters.append(cluster)\n\n                # remove these examples from short term memory\n                for instance in cluster.instances:\n                    index = self.short_mem.index(instance)\n                    y_true = self.short_mem[index].y_true\n                    if y_true is not None:\n                        self.nb_class_unknown[y_true] -= 1\n                    self.short_mem.pop(index)\n\n\n    def _best_threshold(self, new_cluster, closest_cluster, strategy):\n        def run_strategy_1():\n            factor_1 = self.threshold_factor\n            # factor_1 = 5  # good for artificial, separated data sets\n            return factor_1 * np.std(closest_cluster.distance_to_centroid(closest_cluster.instances))\n\n        if strategy == 1:\n            return run_strategy_1()\n        else:\n            factor_2 = factor_3 = self.threshold_factor\n            # factor_2 = factor_3 = 1.2 # good for artificial, separated data sets\n            clusters_same_class = self._get_clusters_in_class(closest_cluster.label)\n            if len(clusters_same_class) == 1:\n                return run_strategy_1()\n            else:\n                class_centroids = np.array([cluster.centroid for cluster in clusters_same_class])\n                distances = closest_cluster.distance_to_centroid(class_centroids)\n                if strategy == 2:\n                    return factor_2 * np.max(distances)\n                elif strategy == 3:\n                    return factor_3 * np.mean(distances)\n\n    def _get_closest_clusters(self, X, centroids):   \n\n        if len(centroids) == 0:\n            print(\"No clusters\")\n            return\n\n        centroids = np.array(centroids)\n        norm_dists = np.zeros((X.shape[0],centroids.shape[0]))\n\n        # Cut into batches if there are too many samples to save on memory\n        for idx in range(math.ceil(X.shape[0]/Minas.MAX_MEMORY_SIZE)):\n            sl = slice(idx*Minas.MAX_MEMORY_SIZE, (idx+1)*Minas.MAX_MEMORY_SIZE)\n            norm_dists[sl] = np.linalg.norm(np.subtract(X[sl, :, None], np.transpose(centroids)), axis=1)\n\n        return np.argmin(norm_dists, axis=1)\n\n    def _get_clusters_in_class(self, label):\n        return [cluster for cluster in self.microclusters if cluster.label == label]\n\n    def _trigger_forget(self):\n        for cluster in self.microclusters:\n            if cluster.timestamp &lt; self.sample_counter - self.window_size:\n                if self.verbose &gt; 1:\n                    print(\"Forgetting cluster: \", cluster)\n                elif self.verbose &gt; 0:\n                    print(\"Forgetting cluster: \", cluster.small_str())\n\n                self.sleep_mem.append(cluster)\n                self.microclusters.remove(cluster)\n        for instance in self.short_mem:\n            if instance.timestamp &lt; self.sample_counter - self.window_size:\n                index = self.short_mem.index(instance)\n                y_true = self.short_mem[index].y_true\n                if y_true is not None:\n                    self.nb_class_unknown[y_true] -= 1\n                self.short_mem.pop(index)\n</code></pre>"},{"location":"reference/model/minas/#streamndr.model.minas.Minas.get_class_unknown_rate","title":"<code>get_class_unknown_rate()</code>","text":"<p>Returns the unknown rate per class. Represents the percentage of unknown samples on the total number of samples of that class seen during the stream.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the unknown rate of each class</p> Source code in <code>streamndr/model/minas.py</code> <pre><code>def get_class_unknown_rate(self):\n    \"\"\"Returns the unknown rate per class. Represents the percentage of unknown samples on the total number of samples of that class seen during the stream.\n\n    Returns\n    -------\n    dict\n        Dictionary containing the unknown rate of each class\n    \"\"\"\n    return {key: val / self.class_sample_counter[key] for key, val in self.nb_class_unknown.items()}\n</code></pre>"},{"location":"reference/model/minas/#streamndr.model.minas.Minas.get_unknown_rate","title":"<code>get_unknown_rate()</code>","text":"<p>Returns the unknown rate, represents the percentage of unknown samples on the total number of samples classified in the online phase.</p> <p>Returns:</p> Type Description <code>float</code> <p>Unknown rate</p> Source code in <code>streamndr/model/minas.py</code> <pre><code>def get_unknown_rate(self):\n    \"\"\"Returns the unknown rate, represents the percentage of unknown samples on the total number of samples classified in the online phase.\n\n    Returns\n    -------\n    float\n        Unknown rate\n    \"\"\"\n    return len(self.short_mem) / self.sample_counter\n</code></pre>"},{"location":"reference/model/minas/#streamndr.model.minas.Minas.learn_many","title":"<code>learn_many(X, y, w=1.0)</code>","text":"<p>Represents the offline phase of the algorithm. Receives a number of samples and their given labels and learns all of the known classes.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame or ndarray</code> <p>Samples to be learned by the model</p> required <code>y</code> <code>list of int</code> <p>Labels corresponding to the given samples, must be the same length as the number of samples</p> required <code>w</code> <code>float</code> <p>Weights, not used, by default 1.0</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Minas</code> <p>Itself</p> Source code in <code>streamndr/model/minas.py</code> <pre><code>def learn_many(self, X, y, w=1.0):\n    \"\"\"Represents the offline phase of the algorithm. Receives a number of samples and their given labels and learns all of the known classes.\n\n    Parameters\n    ----------\n    X : pandas.DataFrame or numpy.ndarray\n        Samples to be learned by the model\n    y : list of int\n        Labels corresponding to the given samples, must be the same length as the number of samples\n    w : float, optional\n        Weights, not used, by default 1.0\n\n    Returns\n    -------\n    Minas\n        Itself\n    \"\"\"\n    if isinstance(X, pd.DataFrame):\n        X = X.to_numpy()\n\n    self.microclusters = self._offline(X, y)\n    self.before_offline_phase = False\n\n    return self\n</code></pre>"},{"location":"reference/model/minas/#streamndr.model.minas.Minas.learn_one","title":"<code>learn_one(x, y, w=1.0)</code>","text":"<p>Function used by river algorithms to learn one sample. It is not applicable to this algorithm since the offline phase requires all samples to arrive at once. It is only added as to follow River's API.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>dict</code> <p>Sample</p> required <code>y</code> <code>int</code> <p>Label of the given sample</p> required <code>w</code> <code>float</code> <p>Weight, not used, by default 1.0</p> <code>1.0</code> Source code in <code>streamndr/model/minas.py</code> <pre><code>def learn_one(self, x, y, w=1.0):\n    \"\"\"Function used by river algorithms to learn one sample. It is not applicable to this algorithm since the offline phase requires all samples\n    to arrive at once. It is only added as to follow River's API.\n\n    Parameters\n    ----------\n    x : dict\n        Sample\n    y : int\n        Label of the given sample\n    w : float, optional\n        Weight, not used, by default 1.0\n    \"\"\"\n    # Not applicable\n    pass\n</code></pre>"},{"location":"reference/model/minas/#streamndr.model.minas.Minas.predict_many","title":"<code>predict_many(X, y=None)</code>","text":"<p>Represents the online phase. Receives multiple samples, for each sample predict its label and adds it to the cluster if it is a known class.  Otherwise, if it's unknown, it is added to the short term memory and novelty detection is performed once the trigger has been reached (min_short_mem_trigger).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame or ndarray</code> <p>Samples</p> required <code>y</code> <code>list of int</code> <p>True y values of the samples, if available. Only used for metric evaluation (UnkRate).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of length len(X) containing the predicted labels, predicts -1 if the corresponding sample labeled as unknown</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the model has not been trained first with learn_many() (offline phase)</p> Source code in <code>streamndr/model/minas.py</code> <pre><code>def predict_many(self, X, y=None):\n    \"\"\"Represents the online phase. Receives multiple samples, for each sample predict its label and adds it to the cluster if it is a known class. \n    Otherwise, if it's unknown, it is added to the short term memory and novelty detection is performed once the trigger has been reached (min_short_mem_trigger).\n\n    Parameters\n    ----------\n    X : pandas.DataFrame or numpy.ndarray\n        Samples\n    y : list of int\n        True y values of the samples, if available. Only used for metric evaluation (UnkRate).\n\n    Returns\n    -------\n    numpy.ndarray\n        Array of length len(X) containing the predicted labels, predicts -1 if the corresponding sample labeled as unknown\n\n    Raises\n    ------\n    Exception\n        If the model has not been trained first with learn_many() (offline phase)\n    \"\"\"\n    if self.before_offline_phase:\n        raise Exception(\"Model must be fitted first\")\n\n    if isinstance(X, pd.DataFrame):\n        X = X.to_numpy() #Converting DataFrame to numpy array\n\n    # Finding closest clusters for received samples\n    closest_clusters = self._get_closest_clusters(X, [microcluster.centroid for microcluster in self.microclusters])\n\n    pred_label = []\n\n    for i in range(len(closest_clusters)):\n        self.sample_counter += 1\n        if y is not None:\n            if y[i] not in self.class_sample_counter:\n                self.class_sample_counter[y[i]] = 1\n            else:\n                self.class_sample_counter[y[i]] += 1\n\n        closest_cluster = self.microclusters[closest_clusters[i]]\n\n        if closest_cluster.encompasses(X[i]):  # classify in this cluster\n            pred_label.append(closest_cluster.label)\n\n            closest_cluster.update_cluster(X[i], self.sample_counter, self.update_summary)\n\n        else:  # classify as unknown\n            pred_label.append(-1)\n\n            if y is not None:\n                self.short_mem.append(ShortMemInstance(X[i], self.sample_counter, y[i]))\n                if y[i] not in self.nb_class_unknown:\n                    self.nb_class_unknown[y[i]] = 1\n                else:\n                    self.nb_class_unknown[y[i]] += 1\n            else:\n                self.short_mem.append(ShortMemInstance(X[i], self.sample_counter))\n\n            if self.verbose &gt; 1:\n                print('Memory length: ', len(self.short_mem))\n            elif self.verbose &gt; 0:\n                if len(self.short_mem) % 100 == 0: print('Memory length: ', len(self.short_mem))\n\n            if len(self.short_mem) &gt;= self.min_short_mem_trigger:\n                self._novelty_detect()\n\n    # forgetting mechanism\n    if self.sample_counter % self.window_size == 0:\n        self._trigger_forget()\n\n\n    return np.array(pred_label)\n</code></pre>"},{"location":"reference/model/minas/#streamndr.model.minas.Minas.predict_one","title":"<code>predict_one(X, y=None)</code>","text":"<p>Represents the online phase. Equivalent to predict_many() with only one sample. Receives only one sample, predict its label and adds  it to the cluster if it is a known class. Otherwise, if it's unknown, it is added to the short term memory and novelty detection is  performed once the trigger has been reached (min_short_mem_trigger).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>dict</code> <p>Sample</p> required <code>y</code> <code>int</code> <p>True y value of the sample, if available. Only used for metric evaluation (UnkRate).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Label predicted for the given sample, predicts -1 if labeled as unknown</p> Source code in <code>streamndr/model/minas.py</code> <pre><code>def predict_one(self, X, y=None):\n    \"\"\"Represents the online phase. Equivalent to predict_many() with only one sample. Receives only one sample, predict its label and adds \n    it to the cluster if it is a known class. Otherwise, if it's unknown, it is added to the short term memory and novelty detection is \n    performed once the trigger has been reached (min_short_mem_trigger).\n\n    Parameters\n    ----------\n    X : dict\n        Sample\n    y : int\n        True y value of the sample, if available. Only used for metric evaluation (UnkRate).\n\n    Returns\n    -------\n    numpy.ndarray\n        Label predicted for the given sample, predicts -1 if labeled as unknown\n    \"\"\"\n    return self.predict_many(np.array(list(X.values()))[None,:], [y])\n</code></pre>"},{"location":"reference/utils/data_structure/","title":"data_structure","text":""},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster","title":"<code>MicroCluster</code>","text":"<p>             Bases: <code>object</code></p> <p>A representation of a cluster with compressed information.</p> <p>Parameters:</p> Name Type Description Default <code>label</code> <code>int</code> <p>Label associated with this microcluster</p> required <code>instances</code> <code>ndarray</code> <p>Instances in this microcluster, preferably these would not be stored if not needed using keep_instances=False</p> <code>None</code> <code>timestamp</code> <code>int</code> <p>Timestamp this microcluster was last updated, used for forgetting mechanisms</p> <code>0</code> <code>keep_instances</code> <code>bool</code> <p>Whether or not to store the instances within the microcluster. Should preferably set to false, but some implementations require access to the instances</p> <code>True</code> <p>Attributes:</p> Name Type Description <code>n</code> <code>int</code> <p>Number of instances stored in this microcluster</p> <code>linear_sum</code> <code>ndarray</code> <p>Linear sum of the points belonging to this microcluster</p> <code>squared_sum</code> <code>ndarray</code> <p>Sum of the squared l2 norms of all samples belonging to this microcluster</p> <code>centroid</code> <code>ndarray</code> <p>Centroid coordinates of the microcluster</p> <code>max_distance</code> <code>ndarray</code> <p>Maximum distance between a point belonging to the microcluster and its centroid</p> <code>mean_distance</code> <code>ndarray</code> <p>Mean distance of the distances between the cluster's points and its centroid</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>class MicroCluster(object):\n    \"\"\"A representation of a cluster with compressed information.\n\n    Parameters\n    ----------\n    label : int\n        Label associated with this microcluster\n    instances : numpy.ndarray\n        Instances in this microcluster, preferably these would not be stored if not needed using keep_instances=False\n    timestamp : int\n        Timestamp this microcluster was last updated, used for forgetting mechanisms  \n    keep_instances : bool\n        Whether or not to store the instances within the microcluster. Should preferably set to false, but some implementations require\n        access to the instances\n\n    Attributes\n    ----------\n    n : int\n        Number of instances stored in this microcluster\n    linear_sum : numpy.ndarray\n        Linear sum of the points belonging to this microcluster\n    squared_sum : numpy.ndarray\n        Sum of the squared l2 norms of all samples belonging to this microcluster\n    centroid : numpy.ndarray\n        Centroid coordinates of the microcluster\n    max_distance : numpy.ndarray\n        Maximum distance between a point belonging to the microcluster and its centroid\n    mean_distance : numpy.ndarray\n        Mean distance of the distances between the cluster's points and its centroid\n    \"\"\"\n\n    def __init__(self,\n                 label,  # the class the microcluster belongs to\n                 instances=None,\n                 timestamp=0, \n                 keep_instances=True #Required True for MINAS\n                 ):\n\n        # TODO: remove instances entirely so it doesn't need to be stored in memory; Might not be possible because of _best_threshold used by MINAS which needs instances\n        super(MicroCluster, self).__init__()\n        self.label = label\n        self.instances = instances\n\n        self.n = len(instances)\n        self.linear_sum = instances.sum(axis=0)\n\n        # Sum of the squared l2 norms of all samples belonging to a microcluster:\n        self.squared_sum = np.square(np.linalg.norm(self.instances, axis=1)).sum()\n        # self.squared_sum = np.square(instances).sum(axis=0)  # From CluSTREAM paper\n\n        self.centroid = self.linear_sum / self.n\n        self.max_distance = np.max(self.distance_to_centroid(instances))\n        self.mean_distance = np.mean(self.distance_to_centroid(instances))\n        self.timestamp = timestamp\n\n        self.update_properties()\n\n        if not keep_instances:\n            self.instances = None\n\n    def __str__(self):\n        \"\"\"Returns string representation of a microcluster.\n\n        Returns\n        -------\n        str\n            String representation of microcluster\n        \"\"\"\n\n        return f\"\"\"Target class {self.label}\n                # of instances: {self.n}\n                Linear sum: {self.linear_sum}\n                Squared sum: {self.squared_sum}\n                Centroid: {self.centroid}\n                Radius: {self.radius}\n                Timestamp of last change: {self.timestamp}\"\"\"\n\n    def small_str(self):\n        \"\"\"Returns string representation of a microcluster.\n\n        Returns\n        -------\n        str\n            Small string representation of microcluster\n        \"\"\"\n\n        return f\"\"\"Target class {self.label}\n                # of instances: {self.n}\n                Timestamp of last change: {self.timestamp}\"\"\"\n\n    def get_radius(self):\n        \"\"\"Returns radius of the microcluster.\n\n        Returns\n        -------\n        float\n            Radius of the microcluster\n        \"\"\"\n\n        factor = 1.5\n        # from BIRCH Wikipedia\n        diff = (self.squared_sum / self.n) - np.dot(self.centroid, self.centroid)\n        if diff &gt; 1e-15:\n            return factor * np.sqrt(diff)\n        else:  # in this case diff should be zero, but sometimes it's an infinitesimal difference\n            return 0\n        # from MINAS paper:\n        #return factor*np.std(self.distance_to_centroid(self.instances))\n\n    def distance_to_centroid(self, X):\n        \"\"\"Returns distance from X to centroid of this cluster.\n\n        Parameters\n        ----------\n        X : numpy.ndarray\n            Point or multiple points\n\n        Returns\n        -------\n        numpy.ndarray\n            Distance from X to the microcluster's centroid\n        \"\"\"\n\n        if len(X.shape) == 1:  # X is only one point\n            return np.linalg.norm(X - self.centroid)\n        else:  # X contains several points\n            return np.linalg.norm(X - self.centroid, axis=1)\n\n    def encompasses(self, X):\n        \"\"\"Checks if point X is inside this microcluster. The point X is considered within the microcluster if the distance \n        between the point and the microcluster's centroid is less than the radius of the microcluster.\n\n        Parameters\n        ----------\n        X : numpy.ndarray\n            One point\n\n        Returns\n        -------\n        bool\n            If the point distance to centroid is contained within the microcluster or not\n        \"\"\"\n\n        return np.less(self.distance_to_centroid(X), self.radius)\n\n    def find_closest_cluster(self, clusters):\n        \"\"\"Finds closest microcluster to this one among passed microclusters.\n\n        Parameters\n        ----------\n        clusters : list of MicroCluster\n\n        Returns\n        -------\n        MicroCluster\n            Closest microcluster\n        \"\"\"\n\n        return min(clusters, key=lambda cl: cl.distance_to_centroid(self.centroid))\n\n    def update_cluster(self, X, timestamp, update_summary):\n        \"\"\"Adds point received in parameter to the cluster and update cluster's centroid if wanted.\n\n        Parameters\n        ----------\n        X : numpy.ndarray\n            One point\n        timestamp : int\n            Timestamp when this point was added to this microcluster\n        update_summary : bool\n            Whether or not to update the microcluster properties with this new point\n        \"\"\"\n\n        assert len(X.shape) == 1  # it's just one point\n        self.timestamp = timestamp\n\n        if self.instances is not None:\n            self.instances = np.append(self.instances, [X],\n                                       axis=0)\n        if update_summary:\n            self.mean_distance = (self.n * self.mean_distance + self.distance_to_centroid(X)) / (self.n + 1)\n            self.n += 1\n            self.linear_sum = np.sum([self.linear_sum, X], axis=0)\n            self.squared_sum = np.sum([self.squared_sum, np.square(X).sum()], axis=0)\n            self.update_properties()\n\n    def update_properties(self):\n        \"\"\"Updates centroid and radius based on current cluster properties.\"\"\"\n        self.centroid = self.linear_sum / self.n\n\n        if self.instances is not None:\n            self.radius = self.get_radius()\n\n            if np.max(self.distance_to_centroid(self.instances)) &gt; self.max_distance:\n                self.max_distance = np.max(self.distance_to_centroid(self.instances))\n\n    def is_cohesive(self, clusters):\n        \"\"\"Verifies if this cluster is cohesive for novelty detection purposes.\n        A new micro-cluster is cohesive if its silhouette coefficient is larger than 0.\n        'b' represents the Euclidean distance between the centroid of the new micro-cluster and the centroid of its\n        closest micro-cluster, and 'a' represents the standard deviation of the distances between the examples of the\n        new micro-cluster and the centroid of the new micro-cluster.\n\n        Parameters\n        ----------\n        clusters : List of MicroCluster\n            Existing known micro-clusters\n\n        Returns\n        -------\n        bool\n            If the cluster is cohesive (silhouette&gt;0) or not\n        \"\"\"\n        b = self.distance_to_centroid(self.find_closest_cluster(clusters).centroid)\n        a = np.std(self.distance_to_centroid(self.instances))\n        silhouette = (b - a) / max(a, b)  # hm, this is always positive if b &gt; a\n        return silhouette &gt; 0\n\n    def is_representative(self, min_examples):\n        \"\"\"Verifies if this cluster is representative for novelty detection purposes.\n        A new micro-cluster is representative if it contains a minimal number of examples,\n        where this number is a user-defined parameter.\n\n        Parameters\n        ----------\n        min_examples : int\n            The number of samples the microcluster needs to have to be considered representative.\n\n        Returns\n        -------\n        bool\n            If the cluster is representative or not\n        \"\"\"\n        return self.n &gt;= min_examples\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.__str__","title":"<code>__str__()</code>","text":"<p>Returns string representation of a microcluster.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of microcluster</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def __str__(self):\n    \"\"\"Returns string representation of a microcluster.\n\n    Returns\n    -------\n    str\n        String representation of microcluster\n    \"\"\"\n\n    return f\"\"\"Target class {self.label}\n            # of instances: {self.n}\n            Linear sum: {self.linear_sum}\n            Squared sum: {self.squared_sum}\n            Centroid: {self.centroid}\n            Radius: {self.radius}\n            Timestamp of last change: {self.timestamp}\"\"\"\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.distance_to_centroid","title":"<code>distance_to_centroid(X)</code>","text":"<p>Returns distance from X to centroid of this cluster.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Point or multiple points</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Distance from X to the microcluster's centroid</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def distance_to_centroid(self, X):\n    \"\"\"Returns distance from X to centroid of this cluster.\n\n    Parameters\n    ----------\n    X : numpy.ndarray\n        Point or multiple points\n\n    Returns\n    -------\n    numpy.ndarray\n        Distance from X to the microcluster's centroid\n    \"\"\"\n\n    if len(X.shape) == 1:  # X is only one point\n        return np.linalg.norm(X - self.centroid)\n    else:  # X contains several points\n        return np.linalg.norm(X - self.centroid, axis=1)\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.encompasses","title":"<code>encompasses(X)</code>","text":"<p>Checks if point X is inside this microcluster. The point X is considered within the microcluster if the distance  between the point and the microcluster's centroid is less than the radius of the microcluster.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>One point</p> required <p>Returns:</p> Type Description <code>bool</code> <p>If the point distance to centroid is contained within the microcluster or not</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def encompasses(self, X):\n    \"\"\"Checks if point X is inside this microcluster. The point X is considered within the microcluster if the distance \n    between the point and the microcluster's centroid is less than the radius of the microcluster.\n\n    Parameters\n    ----------\n    X : numpy.ndarray\n        One point\n\n    Returns\n    -------\n    bool\n        If the point distance to centroid is contained within the microcluster or not\n    \"\"\"\n\n    return np.less(self.distance_to_centroid(X), self.radius)\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.find_closest_cluster","title":"<code>find_closest_cluster(clusters)</code>","text":"<p>Finds closest microcluster to this one among passed microclusters.</p> <p>Parameters:</p> Name Type Description Default <code>clusters</code> <code>list of MicroCluster</code> required <p>Returns:</p> Type Description <code>MicroCluster</code> <p>Closest microcluster</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def find_closest_cluster(self, clusters):\n    \"\"\"Finds closest microcluster to this one among passed microclusters.\n\n    Parameters\n    ----------\n    clusters : list of MicroCluster\n\n    Returns\n    -------\n    MicroCluster\n        Closest microcluster\n    \"\"\"\n\n    return min(clusters, key=lambda cl: cl.distance_to_centroid(self.centroid))\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.get_radius","title":"<code>get_radius()</code>","text":"<p>Returns radius of the microcluster.</p> <p>Returns:</p> Type Description <code>float</code> <p>Radius of the microcluster</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def get_radius(self):\n    \"\"\"Returns radius of the microcluster.\n\n    Returns\n    -------\n    float\n        Radius of the microcluster\n    \"\"\"\n\n    factor = 1.5\n    # from BIRCH Wikipedia\n    diff = (self.squared_sum / self.n) - np.dot(self.centroid, self.centroid)\n    if diff &gt; 1e-15:\n        return factor * np.sqrt(diff)\n    else:  # in this case diff should be zero, but sometimes it's an infinitesimal difference\n        return 0\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.is_cohesive","title":"<code>is_cohesive(clusters)</code>","text":"<p>Verifies if this cluster is cohesive for novelty detection purposes. A new micro-cluster is cohesive if its silhouette coefficient is larger than 0. 'b' represents the Euclidean distance between the centroid of the new micro-cluster and the centroid of its closest micro-cluster, and 'a' represents the standard deviation of the distances between the examples of the new micro-cluster and the centroid of the new micro-cluster.</p> <p>Parameters:</p> Name Type Description Default <code>clusters</code> <code>List of MicroCluster</code> <p>Existing known micro-clusters</p> required <p>Returns:</p> Type Description <code>bool</code> <p>If the cluster is cohesive (silhouette&gt;0) or not</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def is_cohesive(self, clusters):\n    \"\"\"Verifies if this cluster is cohesive for novelty detection purposes.\n    A new micro-cluster is cohesive if its silhouette coefficient is larger than 0.\n    'b' represents the Euclidean distance between the centroid of the new micro-cluster and the centroid of its\n    closest micro-cluster, and 'a' represents the standard deviation of the distances between the examples of the\n    new micro-cluster and the centroid of the new micro-cluster.\n\n    Parameters\n    ----------\n    clusters : List of MicroCluster\n        Existing known micro-clusters\n\n    Returns\n    -------\n    bool\n        If the cluster is cohesive (silhouette&gt;0) or not\n    \"\"\"\n    b = self.distance_to_centroid(self.find_closest_cluster(clusters).centroid)\n    a = np.std(self.distance_to_centroid(self.instances))\n    silhouette = (b - a) / max(a, b)  # hm, this is always positive if b &gt; a\n    return silhouette &gt; 0\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.is_representative","title":"<code>is_representative(min_examples)</code>","text":"<p>Verifies if this cluster is representative for novelty detection purposes. A new micro-cluster is representative if it contains a minimal number of examples, where this number is a user-defined parameter.</p> <p>Parameters:</p> Name Type Description Default <code>min_examples</code> <code>int</code> <p>The number of samples the microcluster needs to have to be considered representative.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>If the cluster is representative or not</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def is_representative(self, min_examples):\n    \"\"\"Verifies if this cluster is representative for novelty detection purposes.\n    A new micro-cluster is representative if it contains a minimal number of examples,\n    where this number is a user-defined parameter.\n\n    Parameters\n    ----------\n    min_examples : int\n        The number of samples the microcluster needs to have to be considered representative.\n\n    Returns\n    -------\n    bool\n        If the cluster is representative or not\n    \"\"\"\n    return self.n &gt;= min_examples\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.small_str","title":"<code>small_str()</code>","text":"<p>Returns string representation of a microcluster.</p> <p>Returns:</p> Type Description <code>str</code> <p>Small string representation of microcluster</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def small_str(self):\n    \"\"\"Returns string representation of a microcluster.\n\n    Returns\n    -------\n    str\n        Small string representation of microcluster\n    \"\"\"\n\n    return f\"\"\"Target class {self.label}\n            # of instances: {self.n}\n            Timestamp of last change: {self.timestamp}\"\"\"\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.update_cluster","title":"<code>update_cluster(X, timestamp, update_summary)</code>","text":"<p>Adds point received in parameter to the cluster and update cluster's centroid if wanted.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>One point</p> required <code>timestamp</code> <code>int</code> <p>Timestamp when this point was added to this microcluster</p> required <code>update_summary</code> <code>bool</code> <p>Whether or not to update the microcluster properties with this new point</p> required Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def update_cluster(self, X, timestamp, update_summary):\n    \"\"\"Adds point received in parameter to the cluster and update cluster's centroid if wanted.\n\n    Parameters\n    ----------\n    X : numpy.ndarray\n        One point\n    timestamp : int\n        Timestamp when this point was added to this microcluster\n    update_summary : bool\n        Whether or not to update the microcluster properties with this new point\n    \"\"\"\n\n    assert len(X.shape) == 1  # it's just one point\n    self.timestamp = timestamp\n\n    if self.instances is not None:\n        self.instances = np.append(self.instances, [X],\n                                   axis=0)\n    if update_summary:\n        self.mean_distance = (self.n * self.mean_distance + self.distance_to_centroid(X)) / (self.n + 1)\n        self.n += 1\n        self.linear_sum = np.sum([self.linear_sum, X], axis=0)\n        self.squared_sum = np.sum([self.squared_sum, np.square(X).sum()], axis=0)\n        self.update_properties()\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.MicroCluster.update_properties","title":"<code>update_properties()</code>","text":"<p>Updates centroid and radius based on current cluster properties.</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def update_properties(self):\n    \"\"\"Updates centroid and radius based on current cluster properties.\"\"\"\n    self.centroid = self.linear_sum / self.n\n\n    if self.instances is not None:\n        self.radius = self.get_radius()\n\n        if np.max(self.distance_to_centroid(self.instances)) &gt; self.max_distance:\n            self.max_distance = np.max(self.distance_to_centroid(self.instances))\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.ShortMemInstance","title":"<code>ShortMemInstance</code>","text":"<p>Instance of a point associated with a timestamp. Used for the buffer memory which stores the unknown samples.</p> <p>Attributes:</p> Name Type Description <code>point</code> <code>ndarray</code> <p>The coordinates of the point</p> <code>timestamp</code> <code>int</code> <p>The timestamp the point was added/treated</p> <code>y_true</code> <code>int</code> <p>The true value of the class</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>class ShortMemInstance:\n    \"\"\"Instance of a point associated with a timestamp. Used for the buffer memory which stores the unknown samples.\n\n    Attributes\n    ----------\n    point : numpy.ndarray\n        The coordinates of the point\n    timestamp : int\n        The timestamp the point was added/treated\n    y_true : int\n        The true value of the class\n    \"\"\"\n    def __init__(self, point, timestamp, y_true=None):\n        self.point = point\n        self.timestamp = timestamp\n        self.y_true = y_true\n\n    def __eq__(self, other):\n        \"\"\"Elements are equal if they have the same values for all variables.\n        This currently does not consider the timestamp.\n\n        Parameters\n        ----------\n        other : ShortMemInstance\n            Other instance to compared to\n\n        Returns\n        -------\n        bool\n            If the instances are equals or not\n        \"\"\"\n        if type(other) == np.ndarray:\n            return np.all(self.point == other)\n</code></pre>"},{"location":"reference/utils/data_structure/#streamndr.utils.data_structure.ShortMemInstance.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Elements are equal if they have the same values for all variables. This currently does not consider the timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>ShortMemInstance</code> <p>Other instance to compared to</p> required <p>Returns:</p> Type Description <code>bool</code> <p>If the instances are equals or not</p> Source code in <code>streamndr/utils/data_structure.py</code> <pre><code>def __eq__(self, other):\n    \"\"\"Elements are equal if they have the same values for all variables.\n    This currently does not consider the timestamp.\n\n    Parameters\n    ----------\n    other : ShortMemInstance\n        Other instance to compared to\n\n    Returns\n    -------\n    bool\n        If the instances are equals or not\n    \"\"\"\n    if type(other) == np.ndarray:\n        return np.all(self.point == other)\n</code></pre>"}]}